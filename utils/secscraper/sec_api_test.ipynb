{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test SEC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class MyLogger:\n",
    "    def __init__(self, name: str = __name__, level: str = 'debug', log_file: str = 'logs.log'):\n",
    "        # Initialize logger\n",
    "        self.logging_level = logging.DEBUG if level == 'debug' else logging.INFO\n",
    "        self.scrape_logger = logging.getLogger(name)\n",
    "        self.scrape_logger.setLevel(self.logging_level)\n",
    "\n",
    "        # Check if the self.scrape_logger already has handlers to avoid duplicate logging.\n",
    "        if not self.scrape_logger.hasHandlers():\n",
    "            # Create a file handler\n",
    "            file_handler = logging.FileHandler(log_file, mode='a')\n",
    "            file_handler.setLevel(self.logging_level)\n",
    "\n",
    "            # Create a stream handler\n",
    "            stream_handler = logging.StreamHandler()\n",
    "            stream_handler.setLevel(self.logging_level)\n",
    "\n",
    "            # Create a logging format\n",
    "            formatter = logging.Formatter(\n",
    "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "            file_handler.setFormatter(formatter)\n",
    "            stream_handler.setFormatter(formatter)\n",
    "\n",
    "            # Add the handlers to the self.scrape_logger\n",
    "            self.scrape_logger.addHandler(file_handler)\n",
    "            self.scrape_logger.addHandler(stream_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import trange\n",
    "import re\n",
    "\n",
    "\n",
    "def convert_keys_to_lowercase(d):\n",
    "    \"\"\"Recursively convert all keys in a dictionary to lowercase.\n",
    "\n",
    "    Args:\n",
    "        d (dict): Dictionary to convert\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with all keys converted to lowercase\n",
    "    \"\"\"\n",
    "    new_dict = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            v = convert_keys_to_lowercase(v)\n",
    "        new_key = re.sub(r'[^a-zA-Z0-9]', '', k.lower())\n",
    "        new_dict[new_key] = v\n",
    "    return new_dict\n",
    "\n",
    "def indexify_url(folder_url: str) -> str:\n",
    "    \"\"\"Converts url to index url.\n",
    "\n",
    "    Args:\n",
    "        url (str): url to convert to index url\n",
    "\n",
    "    Returns:\n",
    "        str: index url\n",
    "    \"\"\"\n",
    "    return folder_url + '/index.json'\n",
    "\n",
    "\n",
    "class SECData(MyLogger):\n",
    "    \"\"\"Class to retrieve data from SEC Edgar database.\n",
    "\n",
    "    Args:\n",
    "        requester_name (str): Name of the requester\n",
    "        requester_email (str): Email of the requester\n",
    "        taxonomy (str): us-gaap, ifrs-full, dei, or srt\n",
    "\n",
    "    Raises:\n",
    "        Exception: If taxonomy is not one of the following: us-gaap, ifrs-full, dei, or srt\n",
    "\n",
    "    Attributes:\n",
    "        BASE_API_URL (str): Base url for SEC Edgar database\n",
    "        US_GAAP_TAXONOMY_URL (str): URL for us-gaap taxonomy\n",
    "        ALLOWED_TAXONOMIES (list): List of allowed taxonomies\n",
    "        headers (dict): Headers to be used for API calls\n",
    "        cik (DataFrame): DataFrame containing CIK and ticker\n",
    "        tags (list): List of tags in us-gaap taxonomy\n",
    "        taxonomy (str): us-gaap, ifrs-full, dei, or srt\n",
    "\n",
    "    Methods:\n",
    "        get_cik_list: Retrieves the full list of CIK available from SEC database.\n",
    "        get_ticker_cik: Get a specific ticker's CIK number. \n",
    "        get_usgaap_tags: Get the list of tags in us-gaap taxonomy.\n",
    "        get_submissions: Retrieves the list of submissions for a specific CIK.\n",
    "        get_company_concept: Retrieves the XBRL disclosures from a single company (CIK) \n",
    "            and concept (a taxonomy and tag) into a single JSON file.\n",
    "        get_company_facts: Retrieves the XBRL disclosures from a single company (CIK) \n",
    "            into a single JSON file.\n",
    "        get_frames: Retrieves one fact for each reporting entity that is last filed that most closely fits the calendrical period requested.\n",
    "    \"\"\"\n",
    "\n",
    "    BASE_API_URL = \"https://data.sec.gov/\"\n",
    "    BASE_SEC_URL = \"https://www.sec.gov/\"\n",
    "    BASE_DIRECTORY_URL = \"https://www.sec.gov/Archives/edgar/data/\"\n",
    "    SIC_LIST_URL = \"https://www.sec.gov/corpfin/division-of-corporation-finance-standard-industrial-classification-sic-code-list\"\n",
    "    US_GAAP_TAXONOMY_URL = \"https://xbrl.fasb.org/us-gaap/2023/elts/us-gaap-2023.xsd\"\n",
    "    ALLOWED_TAXONOMIES = {'us-gaap', 'ifrs-full', 'dei', 'srt'}\n",
    "    INDEX_EXTENSION = {'-index.html', '-index-headers.html'}\n",
    "    DIRECTORY_INDEX = {'index.json', 'index.xml', 'index.html'}\n",
    "    FILE_EXTENSIONS = {'.xsd', '.htm', '_cal.xml',\n",
    "                       '_def.xml', '_lab.xml', '_pre.xml', '_htm.xml', '.xml'}\n",
    "    SCRAPE_FILE_EXTENSIONS = {'_lab','_def','_pre','_cal'}\n",
    "\n",
    "    def __init__(self, requester_company: str = 'Financial API', requester_name: str = 'API Caller', requester_email: str = 'apicaller@gmail.com', taxonomy: str = 'us-gaap',):\n",
    "        super().__init__(name='sec-scraper', level='debug', log_file='././logs.log')\n",
    "\n",
    "        self.requester_company = requester_company\n",
    "        self.requester_name = requester_name\n",
    "        self.requester_email = requester_email\n",
    "        self.sec_headers = {\"User-Agent\": f\"{requester_company} {requester_name} {requester_email}\",\n",
    "                            \"Accept-Encoding\": \"gzip, deflate\",\n",
    "                            \"Host\": \"www.sec.gov\"}\n",
    "        self.sec_data_headers = {\"User-Agent\": f\"{requester_company} {requester_name} {requester_email}\",\n",
    "                                 \"Accept-Encoding\": \"gzip, deflate\",\n",
    "                                 \"Host\": \"data.sec.gov\"}\n",
    "        self._cik_list = None\n",
    "        self._tags = None\n",
    "        if taxonomy not in self.ALLOWED_TAXONOMIES:\n",
    "            raise ValueError(\n",
    "                f\"Taxonomy {taxonomy} is not supported. Please use one of the following taxonomies: {self.ALLOWED_TAXONOMIES}\")\n",
    "        self.taxonomy = taxonomy\n",
    "\n",
    "    @property\n",
    "    def cik_list(self,):\n",
    "        if self._cik_list is None:\n",
    "            self._cik_list = self.get_cik_list()\n",
    "        return self._cik_list\n",
    "\n",
    "    @property\n",
    "    def tags(self,):\n",
    "        if self._tags is None:\n",
    "            self._tags = self.get_usgaap_tags()\n",
    "        return self._tags\n",
    "\n",
    "    @sleep_and_retry\n",
    "    @limits(calls=10, period=1)\n",
    "    def rate_limited_request(self, url: str, headers: dict):\n",
    "        \"\"\"Rate limited request to SEC Edgar database.\n",
    "\n",
    "        Args:\n",
    "            url (str): URL to retrieve data from\n",
    "            headers (dict): Headers to be used for API calls\n",
    "\n",
    "        Returns:\n",
    "            response: Response from API call\n",
    "        \"\"\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            self.scrape_logger.error(f'''Request failed at URL: {url}''')\n",
    "        else:\n",
    "            self.scrape_logger.info(f'''Request successful at URL: {url}''')\n",
    "        return response\n",
    "\n",
    "    def get_cik_list(self):\n",
    "        \"\"\"Retrieves the full list of CIK available from SEC database.\n",
    "\n",
    "        Raises:\n",
    "            Exception: On failure to retrieve CIK list\n",
    "\n",
    "        Returns:\n",
    "            cik_df: DataFrame containing CIK and ticker\n",
    "        \"\"\"\n",
    "        url = r\"https://www.sec.gov/files/company_tickers.json\"\n",
    "        cik_raw = self.rate_limited_request(url, self.sec_headers)\n",
    "        cik_json = cik_raw.json()\n",
    "        cik_df = pd.DataFrame.from_dict(cik_json).T\n",
    "        return cik_df\n",
    "\n",
    "    def get_ticker_cik(self, ticker: str,):\n",
    "        \"\"\"Get a specific ticker's CIK number. \n",
    "        CIK########## is the entity's 10-digit Central Index Key (CIK).\n",
    "\n",
    "        Args:\n",
    "            ticker (str): public ticker symbol of the company\n",
    "\n",
    "        Returns:\n",
    "            cik: CIK number of the company excluding the leading 'CIK'\n",
    "        \"\"\"\n",
    "        ticker_cik = self.cik_list.query(\n",
    "            f\"ticker == '{ticker.upper()}'\")['cik_str']\n",
    "        cik = f\"{ticker_cik.iloc[0]:010d}\"\n",
    "        return cik\n",
    "\n",
    "    def get_usgaap_tags(self, xsd_url: str = US_GAAP_TAXONOMY_URL):\n",
    "        \"\"\"Get the list of tags (elements) in us-gaap taxonomy or provide a different xsd_url to get tags from a different taxonomy.\n",
    "\n",
    "        Returns:\n",
    "            list of tags\n",
    "        \"\"\"\n",
    "        response = self.rate_limited_request(xsd_url, headers=self.sec_headers)\n",
    "        xsd_content = response.text\n",
    "        root = ET.fromstring(xsd_content)\n",
    "\n",
    "        return [element.attrib['name'] for element in root.findall(\".//{http://www.w3.org/2001/XMLSchema}element\")]\n",
    "\n",
    "    def get_submissions(self, cik: str = None, submission_file: str = None) -> dict:\n",
    "        if cik is not None:\n",
    "            url = f\"{self.BASE_API_URL}submissions/CIK{cik}.json\"\n",
    "        elif submission_file is not None:\n",
    "            url = f\"{self.BASE_API_URL}submissions/{submission_file}\"\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Please provide either a CIK number or a submission file.\")\n",
    "        response = self.rate_limited_request(\n",
    "            url, headers=self.sec_data_headers)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                f\"Failed to retrieve submissions. Status code: {response.status_code}\")\n",
    "        data = json.loads(response.text)\n",
    "        return data\n",
    "\n",
    "    def get_company_concept(self, cik: str, tag: str, taxonomy: str = 'us-gaap',):\n",
    "        \"\"\"The company-concept API returns all the XBRL disclosures from a single company (CIK) \n",
    "        and concept (a taxonomy and tag) into a single JSON file, with a separate array of facts \n",
    "        for each units on measure that the company has chosen to disclose \n",
    "        (e.g. net profits reported in U.S. dollars and in Canadian dollars).\n",
    "\n",
    "        Args:\n",
    "            cik (str): CIK number of the company. Get the list using self.cik\n",
    "            taxonomy (str): us-gaap, ifrs-full, dei, or srt\n",
    "            tag (str): taxonomy tag (e.g. Revenue, AccountsPayableCurrent). See full list from https://xbrl.fasb.org/us-gaap/2023/elts/us-gaap-2023.xsd\n",
    "\n",
    "        Raises:\n",
    "            Exception: On failure to retrieve company concept either due to invalid CIK, taxonomy, or tag\n",
    "\n",
    "        Returns:\n",
    "            data: JSON file containing all the XBRL disclosures from a single company (CIK)\n",
    "        \"\"\"\n",
    "        url = f\"{self.BASE_API_URL}api/xbrl/companyconcept/CIK{cik}/{taxonomy}/{tag}.json\"\n",
    "        response = self.rate_limited_request(\n",
    "            url, headers=self.sec_data_headers)\n",
    "        data = json.loads(response.text)\n",
    "        return data\n",
    "\n",
    "    def get_company_facts(self, cik):\n",
    "        url = f\"{self.BASE_API_URL}api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "        response = self.rate_limited_request(\n",
    "            url, headers=self.sec_data_headers)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                f\"Failed to retrieve company facts for CIK {cik}. Status code: {response.status_code}\")\n",
    "        data = json.loads(response.text)\n",
    "        return data\n",
    "\n",
    "    def get_frames(self, taxonomy, tag, unit, period):\n",
    "        \"\"\"The xbrl/frames API aggregates one fact for each reporting entity that is last filed that most closely fits the calendrical period requested. \n",
    "        This API supports for annual, quarterly and instantaneous data: https://data.sec.gov/api/xbrl/frames/us-gaap/AccountsPayableCurrent/USD/CY2019Q1I.json\n",
    "\n",
    "        Args:\n",
    "            taxonomy (str): us-gaap, ifrs-full, dei, or srt\n",
    "            tag (str): taxonomy tag (e.g. Revenue, AccountsPayableCurrent). See full list from https://xbrl.fasb.org/us-gaap/2023/elts/us-gaap-2023.xsd\n",
    "            unit (str): USD, USD-per-shares, etc.\n",
    "            period (str): CY#### for annual data (duration 365 days +/- 30 days), CY####Q# for quarterly data (duration 91 days +/- 30 days), CY####Q#I for instantaneous data\n",
    "\n",
    "        Raises:\n",
    "            Exception: (placeholder)\n",
    "\n",
    "        Returns:\n",
    "            data: json formatted response\n",
    "        \"\"\"\n",
    "        url = f\"{self.BASE_API_URL}api/xbrl/frames/{taxonomy}/{tag}/{unit}/{period}.json\"\n",
    "        response = self.rate_limited_request(\n",
    "            url, headers=self.sec_data_headers)\n",
    "        data = json.loads(response.text)\n",
    "        return data\n",
    "\n",
    "    def get_data_as_dataframe(self, cik: str,):\n",
    "        \"\"\"Retrieves the XBRL disclosures from a single company (CIK) and returns it as a pandas dataframe.\n",
    "\n",
    "        Args:\n",
    "            cik (str): CIK number of the company. Get the list using self.cik\n",
    "\n",
    "        Returns:\n",
    "            df: pandas dataframe containing the XBRL disclosures from a single company (CIK)\n",
    "        \"\"\"\n",
    "        data = self.get_company_facts(cik)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for tag in data['facts'][self.taxonomy]:\n",
    "            facts = data['facts']['us-gaap'][tag]['units']\n",
    "            unit_key = list(facts.keys())[0]\n",
    "            temp_df = pd.DataFrame(facts[unit_key])\n",
    "            temp_df['label'] = tag\n",
    "            df = pd.concat([df, temp_df], axis=0, ignore_index=True)\n",
    "        df = df.astype({'val': 'float64',\n",
    "                        'end': 'datetime64[ns]',\n",
    "                        'start': 'datetime64[ns]',\n",
    "                        'filed': 'datetime64[ns]'})\n",
    "        df['Months Ended'] = (df['end'] - df['start']\n",
    "                              ).dt.days.div(30.4375).round(0)\n",
    "        return df\n",
    "\n",
    "    def get_cik_index(self, cik: str = None,) -> dict:\n",
    "        \"\"\"Each CIK directory and all child subdirectories contain three files to assist in \n",
    "        automated crawling of these directories. \n",
    "        These are not visible through directory browsing.\n",
    "            - index.html (the web browser would normally receive these)\n",
    "            - index.xml (a XML structured version of the same content)\n",
    "            - index.json (a JSON structured vision of the same content)\n",
    "\n",
    "        Args:\n",
    "            cik (str): CIK number of the company. Get the list using self.cik\n",
    "\n",
    "        Returns:\n",
    "            json: pandas dataframe containing the XBRL disclosures from a single company (CIK)\n",
    "        \"\"\"\n",
    "        if cik is not None:\n",
    "            url = self.BASE_DIRECTORY_URL + cik + '/' + 'index.json'\n",
    "\n",
    "        else:\n",
    "            url = self.BASE_DIRECTORY_URL + self.cik + '/' + 'index.json'\n",
    "\n",
    "        response = self.rate_limited_request(url, headers=self.sec_headers)\n",
    "        return response.json()\n",
    "\n",
    "    def get_sic_list(self, sic_list_url: str = SIC_LIST_URL) -> dict:\n",
    "        \"\"\"Get the list of SIC codes from SEC website.\n",
    "\n",
    "        Args:\n",
    "            sic_list_url (str): URL to the list of SIC codes\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing the SIC codes and descriptions\n",
    "        \"\"\"\n",
    "        response = self.rate_limited_request(\n",
    "            sic_list_url, headers=self.sec_headers)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"lxml\")\n",
    "        sic_table = soup.find('table', {'class': 'list'})\n",
    "        sic_list = []\n",
    "        for row in sic_table.find_all('tr')[1:]:\n",
    "            sic_dict = {'_id': None,\n",
    "                        'Office': None, 'Industry Title': None}\n",
    "            sic_dict['_id'] = row.text.split('\\n')[1]\n",
    "            sic_dict['Office'] = row.text.split('\\n')[2]\n",
    "            sic_dict['Industry Title'] = row.text.split('\\n')[3]\n",
    "            sic_list.append(sic_dict)\n",
    "\n",
    "        return sic_list\n",
    "\n",
    "\n",
    "class TickerData(SECData):\n",
    "    \"\"\"Inherited from SECData class. Retrieves data from SEC Edgar database based on ticker.\n",
    "    url is constructed based on the following: https://www.sec.gov/Archives/edgar/data/{cik}/{ascension_number}/{file_name}\n",
    "    cik is the CIK number of the company = access via get_ticker_cik\n",
    "    ascension_number is the accessionNumber column of filings_df\n",
    "    file name for xml is always '{ticker}-{reportDate}.{extension}\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ticker: str, requester_company: str = 'Financial API', requester_name: str = 'API Caller', requester_email: str = 'apicaller@gmail.com', taxonomy: str = 'us-gaap',):\n",
    "        super().__init__(requester_company, requester_name, requester_email, taxonomy)\n",
    "        self.ticker = ticker.upper()\n",
    "        self.cik = self.get_ticker_cik(self.ticker)\n",
    "        self._submissions = self.get_submissions(self.cik)\n",
    "        self._filings = None\n",
    "        self._forms = None\n",
    "        self._index = self.get_cik_index(self.cik)\n",
    "        self._filing_folder_urls = None\n",
    "        self._filing_urls = None\n",
    "\n",
    "    @property\n",
    "    def submissions(self,) -> dict:\n",
    "        if self._submissions is not None:\n",
    "            self._submissions['cik'] = self.cik\n",
    "            self._submissions['filings'] = self.filings.replace(\n",
    "                {pd.NaT: None}).to_dict('records')\n",
    "        return self._submissions\n",
    "\n",
    "    @property\n",
    "    def filings(self,) -> pd.DataFrame:\n",
    "        if self._filings is None:\n",
    "            self._filings = self.get_filings()\n",
    "        return self._filings\n",
    "\n",
    "    @property\n",
    "    def latest_filing(self,) -> pd.DataFrame:\n",
    "        return self.filings.iloc[0, :].to_dict() if len(self.filings) > 0 else None\n",
    "\n",
    "    @property\n",
    "    def latest_10Q(self,) -> pd.DataFrame:\n",
    "        return self.filings.query(\"form == '10-Q'\").iloc[0, :].to_dict() if len(self.filings.query(\"form == '10-Q'\")) > 0 else None\n",
    "\n",
    "    @property\n",
    "    def latest_10K(self,) -> pd.DataFrame:\n",
    "        return self.filings.query(\"form == '10-K'\").iloc[0, :].to_dict() if len(self.filings.query(\"form == '10-K'\")) > 0 else None\n",
    "\n",
    "    @property\n",
    "    def latest_8K(self,) -> pd.DataFrame:\n",
    "        return self.filings.query(\"form == '8-K'\").iloc[0, :].to_dict() if len(self.filings.query(\"form == '8-K'\")) > 0 else None\n",
    "\n",
    "    @property\n",
    "    def filing_folder_urls(self,) -> list:\n",
    "        if self._filing_folder_urls is None:\n",
    "            self._filing_folder_urls = self._get_filing_folder_urls()\n",
    "        return self._filing_folder_urls\n",
    "\n",
    "    @property\n",
    "    def filing_urls(self,) -> list:\n",
    "        if self._filing_urls is None:\n",
    "            self._filing_urls = self.filings['file_url'].tolist()\n",
    "\n",
    "        return self._filing_urls\n",
    "\n",
    "    @property\n",
    "    def forms(self,) -> list:\n",
    "        if self._forms is None:\n",
    "            self._forms = self.filings['form'].unique()\n",
    "        return self._forms\n",
    "\n",
    "    def _get_filing_folder_urls(self,) -> list:\n",
    "        \"\"\"Get filing folder urls from index dict.\n",
    "\n",
    "        Args:\n",
    "            index (dict): index dict from get_index method\n",
    "\n",
    "        Returns:s\n",
    "            filing_folder_urls (list): list of filing folder urls\n",
    "        \"\"\"\n",
    "\n",
    "        filing_folder_urls = [self.BASE_SEC_URL + self._index['directory']['name'] + '/' + folder['name']\n",
    "                              for folder in self._index['directory']['item'] if folder['type'] == 'folder.gif']\n",
    "        return filing_folder_urls\n",
    "\n",
    "    def _get_filing_urls(self,) -> list:\n",
    "        \"\"\"(DEPRECATED)\n",
    "        ---The filing urls are implemented in the get_filings method.---\n",
    "\n",
    "        Get filing urls from filing folder urls.\n",
    "\n",
    "        Args:\n",
    "            filing_folder_urls (list): list of filing folder urls\n",
    "\n",
    "        Returns:\n",
    "            filing_urls (list): list of filing urls to .txt files\n",
    "        \"\"\"\n",
    "        filing_urls = []\n",
    "        with trange(len(self.filing_folder_urls), desc=f'Instantiating filing urls for {self.ticker}...') as t:\n",
    "            for i in t:\n",
    "                self.scrape_logger.info(t)\n",
    "                try:\n",
    "                    soup = self.get_file_data(self.filing_folder_urls[i])\n",
    "                    for link in soup.find_all('a'):\n",
    "                        if link.get('href').endswith('.txt'):\n",
    "                            filing_urls.append(\n",
    "                                self.BASE_SEC_URL + link.get('href'))\n",
    "                except Exception as e:\n",
    "                    self.scrape_logger.error(\n",
    "                        f'Failed to instantiate filing urls for {self.ticker}...')\n",
    "                    self.scrape_logger.error(e)\n",
    "                    t.write(\n",
    "                        f'Failed to instantiate filing urls for {self.ticker}...')\n",
    "                    continue\n",
    "        return filing_urls\n",
    "\n",
    "    def get_filing_folder_index(self, folder_url: str, return_df: bool = True) -> dict | pd.DataFrame:\n",
    "        \"\"\"Get filing folder index from folder url.\n",
    "\n",
    "        Args:\n",
    "            folder_url (str): folder url to retrieve data from\n",
    "            return_df (bool, optional): Whether to return a DataFrame or dict. Defaults to True.\n",
    "        \n",
    "        Returns:\n",
    "            index (dict): index dict or dataframe\n",
    "        \"\"\"\n",
    "        index_url = indexify_url(folder_url)\n",
    "        index = self.rate_limited_request(index_url, headers=self.sec_headers)\n",
    "        return pd.DataFrame(index.json()['directory']['item']) if return_df else index.json()['directory']['item']\n",
    "\n",
    "    def get_filings(self,) -> dict:\n",
    "        \"\"\"Get filings and urls to .txt from submissions dict.\n",
    "\n",
    "        Args:\n",
    "            submissions (dict): submissions dict from get_submissions method\n",
    "\n",
    "        Returns:\n",
    "            filings (dict): dictionary containing filings\n",
    "        \"\"\"\n",
    "        self.scrape_logger.info(\n",
    "            f'Making http request for {self.ticker} filings...')\n",
    "        filings = self._submissions['filings']['recent']\n",
    "\n",
    "        if len(self._submissions['filings']) > 1:\n",
    "            self.scrape_logger.info(\n",
    "                f'Additional filings found for {self.ticker}...')\n",
    "            for file in self._submissions['filings']['files']:\n",
    "                additional_filing = self.get_submissions(\n",
    "                    submission_file=file['name'])\n",
    "                filings = {key: filings[key] + additional_filing[key]\n",
    "                           for key in filings.keys()}\n",
    "\n",
    "        filings = pd.DataFrame(filings)\n",
    "        # Convert reportDate, filingDate, acceptanceDateTime columns to datetime\n",
    "        filings['reportDate'] = pd.to_datetime(filings['reportDate'])\n",
    "        filings['filingDate'] = pd.to_datetime(filings['filingDate'])\n",
    "        filings['acceptanceDateTime'] = pd.to_datetime(\n",
    "            filings['acceptanceDateTime'])\n",
    "        filings['cik'] = self.cik\n",
    "\n",
    "        filings = filings.loc[~pd.isnull(filings['reportDate'])]\n",
    "\n",
    "        # get folder url for each row\n",
    "        filings['folder_url'] = self.BASE_DIRECTORY_URL + \\\n",
    "            self.cik + '/' + filings['accessionNumber'].str.replace('-', '')\n",
    "\n",
    "        # get file url for each row\n",
    "        filings['file_url'] = filings['folder_url'] + \\\n",
    "            '/' + filings['accessionNumber'] + '.txt'\n",
    "\n",
    "        return filings\n",
    "\n",
    "    def get_file_data(self, file_url: str) -> BeautifulSoup:\n",
    "        \"\"\"Get file data from file url which can be retrieved by calling self.get_file_url method.\n",
    "\n",
    "        Args:\n",
    "            file_url (str): File url to retrieve data from on the SEC website\n",
    "\n",
    "        Returns:\n",
    "            data: File data as a BeautifulSoup object\n",
    "        \"\"\"\n",
    "        data = self.rate_limited_request(\n",
    "            url=file_url, headers=self.sec_headers)\n",
    "        try:\n",
    "            soup = BeautifulSoup(data.content, \"lxml\")\n",
    "            self.scrape_logger.info(\n",
    "                f'Parsed file data from {file_url} successfully.')\n",
    "            return soup\n",
    "\n",
    "        except Exception as e:\n",
    "            self.scrape_logger.error(\n",
    "                f'Failed to parse file data from {file_url}. Error: {e}')\n",
    "            raise Exception(\n",
    "                f'Failed to parse file data from {file_url}. Error: {e}')\n",
    "\n",
    "    # TODO: replace search_xxx methods with strategy pattern\n",
    "\n",
    "    def get_elements(self, folder_url: str, index_df: pd.DataFrame, scrape_file_extension: str) -> pd.DataFrame:\n",
    "        \"\"\"Get elements from .xml files from folder_url.\n",
    "\n",
    "        Args:\n",
    "            folder_url (str): folder url to retrieve data from\n",
    "            index_df (pd.DataFrame): dataframe containing files in the filing folder\n",
    "            scrape_file_extension (str): .xml file extension to scrape\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: returns a dataframe containing the elements, attributes, text\n",
    "        \"\"\"\n",
    "        xml = index_df.query(f\"name.str.contains('{scrape_file_extension}')\")\n",
    "        xml_content = self.rate_limited_request(folder_url + '/' + xml['name'].iloc[0], headers=self.sec_headers).content\n",
    "\n",
    "        xml_soup = BeautifulSoup(xml_content, 'lxml-xml')\n",
    "        labels = xml_soup.find_all()\n",
    "        labels_list = []\n",
    "        for i in labels[1:]:\n",
    "            label_dict = dict(**i.attrs, labelText=i.text.strip())\n",
    "            labels_list.append(label_dict)\n",
    "        return pd.DataFrame(labels_list)\n",
    "    \n",
    "    def search_tags(self, soup: BeautifulSoup, pattern: str) -> BeautifulSoup:\n",
    "        \"\"\"Search for tags in BeautifulSoup object.\n",
    "\n",
    "        Args:\n",
    "            soup (BeautifulSoup): BeautifulSoup object\n",
    "            pattern (str): regex pattern to search for\n",
    "\n",
    "        Returns:\n",
    "            soup: BeautifulSoup object\n",
    "        \"\"\"\n",
    "        return soup.find_all(re.compile(pattern))\n",
    "\n",
    "    def search_context(self, soup: BeautifulSoup) -> pd.DataFrame:\n",
    "        \"\"\"Search for context in company .txt filing. \n",
    "        Context provides information about the entity, segment, and time period for facts in the filing.\n",
    "\n",
    "        Args:\n",
    "            soup (BeautifulSoup): BeautifulSoup object\n",
    "\n",
    "        Returns:\n",
    "            df: DataFrame containing context information with columns \n",
    "            {\n",
    "                'contextId': str,\n",
    "                'entity': str,\n",
    "                'segment': str,\n",
    "                'startDate': 'datetime64[ns]',\n",
    "                'endDate': 'datetime64[ns]',\n",
    "                'instant': 'datetime64[ns]'\n",
    "            }\n",
    "        \"\"\"\n",
    "        contexts = self.search_tags(soup, '^context$')\n",
    "        dict_list = []\n",
    "        columns = {'contextId': str, 'entity': str, 'segment': str,\n",
    "                   'startDate': 'datetime64[ns]', 'endDate': 'datetime64[ns]', 'instant': 'datetime64[ns]'}\n",
    "        for tag in contexts:\n",
    "            temp_dict = {}\n",
    "            temp_dict['contextId'] = tag.attrs.get('id')\n",
    "            temp_dict['entity'] = tag.find(\"entity\").text.split()[\n",
    "                0] if tag.find(\"entity\") is not None else None\n",
    "            temp_dict['segment'] = tag.find(\"segment\").text.strip(\n",
    "            ) if tag.find(\"segment\") is not None else None\n",
    "            temp_dict['startDate'] = tag.find(\"startdate\").text if tag.find(\n",
    "                \"startdate\") is not None else None\n",
    "            temp_dict['endDate'] = tag.find(\"enddate\").text if tag.find(\n",
    "                \"enddate\") is not None else None\n",
    "            temp_dict['instant'] = tag.find(\"instant\").text if tag.find(\n",
    "                \"instant\") is not None else None\n",
    "            dict_list.append(temp_dict)\n",
    "\n",
    "        df = pd.DataFrame(dict_list, columns=columns.keys()).astype(columns)\n",
    "        return df\n",
    "\n",
    "    def search_linklabels(self, soup: BeautifulSoup) -> pd.DataFrame:\n",
    "        \"\"\"Search for link labels in company .txt filing. \n",
    "        Link labels provide information about the relationship between facts and their corresponding concepts.\n",
    "\n",
    "        Args:\n",
    "            soup (BeautifulSoup): BeautifulSoup object\n",
    "\n",
    "        Returns:\n",
    "            df: DataFrame containing link label information with columns \n",
    "            {\n",
    "                'linkLabelId': str,\n",
    "                'xlinkLabel': str,\n",
    "                'xlinkRole': str,\n",
    "                'xlinkType': str,\n",
    "                'xlmnsXml': str,\n",
    "                'xmlLang': str,\n",
    "                'label': str\n",
    "            }\n",
    "        \"\"\"\n",
    "        links = self.search_tags(soup, '^link:label$')\n",
    "        dict_list = []\n",
    "        columns = {'linkLabelId': str, 'xlinkLabel': str, 'xlinkRole': str,\n",
    "                   'xlinkType': str, 'xlmnsXml': str, 'xmlLang': str, 'label': str}\n",
    "\n",
    "        for tag in links:\n",
    "            temp_dict = {}\n",
    "            temp_dict['linkLabelId'] = tag.attrs.get('id')\n",
    "            temp_dict['xlinkLabel'] = tag.attrs.get('xlink:label')\n",
    "            temp_dict['xlinkRole'] = tag.attrs.get('xlink:role')\n",
    "            temp_dict['xlinkType'] = tag.attrs.get('xlink:type')\n",
    "            temp_dict['xlmnsXml'] = tag.attrs.get('xmlns:xml')\n",
    "            temp_dict['xmlLang'] = tag.attrs.get('xml:lang')\n",
    "            temp_dict['label'] = tag.text if tag.text is not None else None\n",
    "            dict_list.append(temp_dict)\n",
    "\n",
    "        df = pd.DataFrame(dict_list, columns=columns.keys()).astype(columns)\n",
    "        return df\n",
    "\n",
    "    def search_facts(self, soup: BeautifulSoup) -> pd.DataFrame:\n",
    "        \"\"\"Search for facts in company .txt filing. \n",
    "        Facts provide the actual data values for the XBRL disclosures.\n",
    "\n",
    "        Args:\n",
    "            soup (BeautifulSoup): BeautifulSoup object\n",
    "\n",
    "        Returns:\n",
    "            df: DataFrame containing fact information with columns \n",
    "            {\n",
    "                'factName': str,\n",
    "                'contextRef': str,\n",
    "                'decimals': int,\n",
    "                'factId': str,\n",
    "                'unitRef': str,\n",
    "                'value': str\n",
    "            }\n",
    "        \"\"\"\n",
    "        facts = self.search_tags(soup, '^us-gaap:')\n",
    "        dict_list = []\n",
    "        columns = {'factName': str, 'contextRef': str, 'decimals': int, 'factId': str,\n",
    "                   'unitRef': str, 'value': str}\n",
    "\n",
    "        for tag in facts:\n",
    "            temp_dict = {}\n",
    "            temp_dict['factName'] = tag.name\n",
    "            temp_dict['contextRef'] = tag.attrs.get('contextref')\n",
    "            temp_dict['decimals'] = tag.attrs.get('decimals')\n",
    "            temp_dict['factId'] = tag.attrs.get('id')\n",
    "            temp_dict['unitRef'] = tag.attrs.get('unitref')\n",
    "            temp_dict['value'] = tag.text\n",
    "            dict_list.append(temp_dict)\n",
    "\n",
    "        df = pd.DataFrame(dict_list, columns=columns.keys())\n",
    "        return df\n",
    "\n",
    "    def get_metalinks(self, metalinks_url: str) -> pd.DataFrame:\n",
    "        \"\"\"Get metalinks from metalinks url.\n",
    "\n",
    "        Args:\n",
    "            metalinks_url (str): metalinks url to retrieve data from\n",
    "\n",
    "        Returns:\n",
    "            df: DataFrame containing metalinks information with columns \n",
    "            {\n",
    "                'labelKey': str,\n",
    "                'localName': str,\n",
    "                'labelName': int,\n",
    "                'terseLabel': str,\n",
    "                'documentation': str,\n",
    "            }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.rate_limited_request(\n",
    "                url=metalinks_url, headers=self.sec_headers).json()\n",
    "            metalinks_instance = convert_keys_to_lowercase(\n",
    "                response['instance'])\n",
    "            instance_key = list(metalinks_instance.keys())[0]\n",
    "            dict_list = []\n",
    "            for i in metalinks_instance[instance_key]['tag']:\n",
    "                dict_list.append(dict(labelKey=i.lower(),\n",
    "                                      localName=metalinks_instance[instance_key]['tag'][i].get(\n",
    "                                          'localname'),\n",
    "                                      labelName=metalinks_instance[instance_key]['tag'][i].get(\n",
    "                                          'lang').get('enus').get('role').get('label'),\n",
    "                                      terseLabel=metalinks_instance[instance_key]['tag'][i].get(\n",
    "                                          'lang').get('enus').get('role').get('terselabel'),\n",
    "                                      documentation=metalinks_instance[instance_key]['tag'][i].get('lang').get('enus').get('role').get('documentation'),))\n",
    "\n",
    "            df = pd.DataFrame.from_dict(dict_list)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            self.scrape_logger.error(\n",
    "                f'Failed to retrieve metalinks from {metalinks_url}. Error: {e}')\n",
    "            return None\n",
    "\n",
    "    def get_facts_for_each_filing(self, filing: dict) -> dict:\n",
    "        \"\"\"Get facts for each filing.\n",
    "\n",
    "        Args:\n",
    "            filing_url (str): filing url to retrieve data from (link to .txt file in filing directory)\n",
    "            folder_url (str): folder url to retrieve data from (link to filing directory)\n",
    "        Returns:\n",
    "            df: DataFrame containing facts information with columns \n",
    "            {\n",
    "                'factName': str,\n",
    "                'contextRef': str,\n",
    "                'decimals': int,\n",
    "                'factId': str,\n",
    "                'unitRef': str,\n",
    "                'value': str,\n",
    "                'contextId': str,\n",
    "                'entity': str,\n",
    "                'segment': str,\n",
    "                'startDate': 'datetime64[ns]',\n",
    "                'endDate': 'datetime64[ns]',\n",
    "                'instant': 'datetime64[ns]',\n",
    "                # 'labelKey': str,\n",
    "                # 'localName': str,\n",
    "                # 'labelName': int,\n",
    "                # 'terseLabel': str,\n",
    "                # 'documentation': str,\n",
    "                'accessionNumber': str,\n",
    "            }\n",
    "        \"\"\"\n",
    "        columns_to_keep = ['factName', 'contextRef', 'decimals', 'factId', 'unitRef', 'value', 'segment', 'startDate',\n",
    "                           'endDate', 'instant', 'accessionNumber']\n",
    "        soup = self.get_file_data(filing['file_url'])\n",
    "        facts = self.search_facts(soup)\n",
    "        context = self.search_context(soup)\n",
    "        # metalinks = self.get_metalinks(\n",
    "        #     filing['folder_url'] + '/MetaLinks.json')\n",
    "\n",
    "        # if metalinks is None:\n",
    "        #     return None\n",
    "        context['segment'] = context['segment'].str.replace(\n",
    "            pat=r'[^a-zA-Z0-9]', repl='', regex=True).str.lower()\n",
    "        df = facts.merge(context, how='left', left_on='contextRef', right_on='contextId')\n",
    "            # .merge(metalinks, how='left', left_on='segment', right_on='labelKey')\n",
    "\n",
    "        df['ticker'] = self.ticker\n",
    "        df['cik'] = self.cik\n",
    "        df['accessionNumber'] = filing['accessionNumber']\n",
    "\n",
    "        df = df.loc[~df['unitRef'].isnull(), columns_to_keep].replace({\n",
    "            pd.NaT: None})\n",
    "\n",
    "        return facts, context, df.to_dict('records')\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        class_name = type(self).__name__\n",
    "        main_attrs = ['ticker', 'cik', 'submissions', 'filings']\n",
    "        available_methods = [method_name for method_name in dir(self) if callable(\n",
    "            getattr(self, method_name)) and not method_name.startswith(\"_\")]\n",
    "        return f\"\"\"{class_name}({self.ticker})\n",
    "    CIK: {self.cik}\n",
    "    Latest filing: {self.latest_filing['filingDate'].strftime('%Y-%m-%d') if self.latest_filing else 'No filing found'} for Form {self.latest_filing['form'] if self.latest_filing else None}. Access via: {self.latest_filing['folder_url'] if self.latest_filing else None}\n",
    "    Latest 10-Q: {self.latest_10Q['filingDate'].strftime('%Y-%m-%d') if self.latest_10Q else 'No filing found'}. Access via: {self.latest_10Q['folder_url'] if self.latest_10Q else None}\n",
    "    Latest 10-K: {self.latest_10K['filingDate'].strftime('%Y-%m-%d') if self.latest_10K else 'No filing found'}. Access via: {self.latest_10K['folder_url'] if self.latest_10K else None}\"\"\"\n",
    "\n",
    "    def __repr_html__(self) -> str:\n",
    "        class_name = type(self).__name__\n",
    "        main_attrs = ['ticker', 'cik', 'submissions', 'filings']\n",
    "        available_methods = [method_name for method_name in dir(self) if callable(\n",
    "            getattr(self, method_name)) and not method_name.startswith(\"_\")]\n",
    "        latest_filing_date = self.latest_filing['filingDate'].strftime(\n",
    "            '%Y-%m-%d') if self.latest_filing else 'No filing found'\n",
    "        latest_filing_form = self.latest_filing['form'] if self.latest_filing else None\n",
    "        latest_filing_folder_url = self.latest_filing['folder_url'] if self.latest_filing else None\n",
    "        latest_10Q_date = self.latest_10Q['filingDate'].strftime(\n",
    "            '%Y-%m-%d') if self.latest_10Q else 'No filing found'\n",
    "        latest_10Q_folder_url = self.latest_10Q['folder_url'] if self.latest_10Q else None\n",
    "        latest_10K_date = self.latest_10K['filingDate'].strftime(\n",
    "            '%Y-%m-%d') if self.latest_10K else 'No filing found'\n",
    "        latest_10K_folder_url = self.latest_10K['folder_url'] if self.latest_10K else None\n",
    "        return f\"\"\"\n",
    "        <div style=\"border: 1px solid #ccc; padding: 10px; margin: 10px;\">\n",
    "            <h3>{self.submissions['name']}</h3>\n",
    "            <h5>{self.submissions['sicDescription']}</h5>\n",
    "            <p><strong>Ticker:</strong> {self.ticker}</p>\n",
    "            <p><strong>CIK:</strong> {self.cik}</p>\n",
    "            <p><strong>Latest filing:</strong> {latest_filing_date} for Form {latest_filing_form}. Access via: <a href=\"{latest_filing_folder_url}\">{latest_filing_folder_url}</a></p>\n",
    "            <p><strong>Latest 10-Q:</strong> {latest_10Q_date}. Access via: <a href=\"{latest_10Q_folder_url}\">{latest_10Q_folder_url}</a></p>\n",
    "            <p><strong>Latest 10-K:</strong> {latest_10K_date}. Access via: <a href=\"{latest_10K_folder_url}\">{latest_10K_folder_url}</a></p>\n",
    "        </div>\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, ASCENDING, IndexModel, UpdateOne\n",
    "from pymongo.errors import OperationFailure\n",
    "from dotenv import load_dotenv\n",
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class SECDatabase(MyLogger):\n",
    "    def __init__(self, connection_string):\n",
    "        super().__init__(name='SECDatabase', level='DEBUG', log_file='././logs.log')\n",
    "        self.client = MongoClient(connection_string)\n",
    "        self.db = self.client.SECRawData\n",
    "        self.tickerdata = self.db.TickerData\n",
    "        self.tickerfilings = self.db.TickerFilings\n",
    "        self.sicdb = self.db.SICList\n",
    "        self.factsdb = self.db.Facts\n",
    "        try:\n",
    "            self.tickerdata.create_indexes(\n",
    "                [IndexModel([('cik', ASCENDING)], unique=True)])\n",
    "        except OperationFailure as e:\n",
    "            self.scrape_logger.error(e)\n",
    "\n",
    "        try:\n",
    "            self.tickerfilings.create_indexes([IndexModel(\n",
    "                [('accessionNumber', ASCENDING)], unique=True), IndexModel([('form', ASCENDING)])])\n",
    "        except OperationFailure as e:\n",
    "            self.scrape_logger.error(e)\n",
    "\n",
    "        try:\n",
    "            self.factsdb.create_indexes(\n",
    "                [IndexModel([('factId', ASCENDING)], unique=True)])\n",
    "\n",
    "        except OperationFailure as e:\n",
    "            self.scrape_logger.error(e)\n",
    "\n",
    "    @property\n",
    "    def get_server_info(self):\n",
    "        return self.client.server_info()\n",
    "\n",
    "    @property\n",
    "    def get_collection_names(self):\n",
    "        return self.db.list_collection_names()\n",
    "\n",
    "    @property\n",
    "    def get_tickerdata_index_information(self):\n",
    "        return self.tickerdata.index_information()\n",
    "\n",
    "    @property\n",
    "    def get_tickerfilings_index_information(self):\n",
    "        return self.tickerfilings.index_information()\n",
    "\n",
    "    def get_tickerdata(self, cik: str = None, ticker: str = None):\n",
    "        if cik is not None:\n",
    "            return self.tickerdata.find_one({'cik': cik})\n",
    "        elif ticker is not None:\n",
    "            return self.tickerdata.find_one({'tickers': ticker.upper()})\n",
    "        else:\n",
    "            raise Exception('Please provide either a CIK or ticker.')\n",
    "\n",
    "    def update_sic_list(self, sic_list: list) -> None:\n",
    "        \"\"\"Update SIC list in SEC database.\n",
    "\n",
    "        Args:\n",
    "            sic_list (list): List of SIC codes and descriptions\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for i in range(len(sic_list)):\n",
    "                self.sicdb.update_one({'_id': sic_list[i]['_id']}, {'$set': sic_list[i]}, upsert=True)\n",
    "            self.scrape_logger.info(\n",
    "                f'Successfully updated SIC list in SEC database.')\n",
    "        except Exception as e:\n",
    "            self.scrape_logger.error(\n",
    "                f'Failed to update SIC list in SEC database. Error: {e}')\n",
    "        return None\n",
    "\n",
    "    def insert_submission(self, submission: dict):\n",
    "        \"\"\"Insert submissions into SEC database.\n",
    "\n",
    "        Args:\n",
    "            ticker (TickerData): TickerData object\n",
    "\n",
    "        Returns:\n",
    "            str: empty string if successful\n",
    "            str: ticker's cik if failed\n",
    "        \"\"\"\n",
    "        submission['lastUpdated'] = dt.datetime.now()\n",
    "        try:\n",
    "            self.tickerdata.update_one({'cik': submission['cik']}, {\n",
    "                                       '$set': submission}, upsert=True)\n",
    "            self.scrape_logger.info(\n",
    "                f'Inserted submissions for {submission[\"cik\"]} into SEC database.')\n",
    "\n",
    "        except Exception as e:\n",
    "            self.scrape_logger.error(\n",
    "                f'Failed to insert submissions for {submission[\"cik\"]} into SEC database. Error: {e}')\n",
    "            return submission['cik']\n",
    "        return None\n",
    "\n",
    "    def insert_filings(self, cik: str, filings: list):\n",
    "        \"\"\"Insert filings into SEC database. Each submission has many filings.\n",
    "\n",
    "        Args:\n",
    "            ticker (TickerData): TickerData object\n",
    "\n",
    "        Returns:\n",
    "            str: empty string if successful\n",
    "            str: ticker's cik if failed\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for doc in filings:\n",
    "                doc['lastUpdated'] = dt.datetime.now()\n",
    "\n",
    "            update_requests = [UpdateOne({'accessionNumber': doc['accessionNumber']}, {\n",
    "                                         '$set': doc}, upsert=True) for doc in filings]\n",
    "\n",
    "            self.tickerfilings.bulk_write(update_requests)\n",
    "            self.scrape_logger.info(\n",
    "                f'Sucessfully updated filings for {cik}...')\n",
    "\n",
    "        except Exception as e:\n",
    "            self.scrape_logger.error(\n",
    "                f'Failed to insert filings for {cik}...{e}')\n",
    "            return cik\n",
    "        return None\n",
    "\n",
    "    def insert_facts(self, accession: str, facts: list):\n",
    "        \"\"\"Insert facts into SEC database. Each filing has many facts.\n",
    "\n",
    "        Args:\n",
    "            facts (list): A list containing facts for a single filing\n",
    "\n",
    "        Returns:\n",
    "            str: empty string if successful\n",
    "            str: ticker's cik if failed\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for doc in facts:\n",
    "                doc['lastUpdated'] = dt.datetime.now()\n",
    "\n",
    "            fact_update_requests = [UpdateOne({'factId': fact['factId']}, {\n",
    "                                              '$set': fact}, upsert=True) for fact in facts]\n",
    "\n",
    "            self.factsdb.bulk_write(fact_update_requests)\n",
    "            self.scrape_logger.info(f'Updated facts for {accession}...')\n",
    "\n",
    "        except Exception as e:\n",
    "            self.scrape_logger.error(\n",
    "                f'Failed to insert facts for {accession}...{e}')\n",
    "            return accession\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = SECData()\n",
    "mongo = SECDatabase(os.getenv('mongodb_sec'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to insert submission, filings, and facts for each filing into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = SECData()\n",
    "sic_dict = sec.get_sic_list()\n",
    "mongo = SECDatabase(connection_string=os.getenv('mongodb_sec'))\n",
    "\n",
    "failed_submissions = []\n",
    "failed_filings = []\n",
    "failed_facts = []\n",
    "\n",
    "with trange(len(sec.cik_list['ticker'][:50]), desc='Instantiating ticker...',) as t:\n",
    "    for item in t:\n",
    "        ticker = sec.cik_list['ticker'].iloc[item] # Get ticker from cik_list\n",
    "        t.set_postfix(ticker=ticker, cik=sec.cik_list['cik_str'].iloc[item])\n",
    "\n",
    "        # Initialize and instantiate TickerData object\n",
    "        try:\n",
    "            symbol = TickerData(ticker=ticker)\n",
    "            cik = symbol.cik # get cik of ticker\n",
    "            symbol.submissions['lastUpdated'] = dt.datetime.now()\n",
    "            symbol.submissions['office'] = mongo.sicdb.find_one({'_id': symbol.submissions['sic']})['Office']\n",
    "            sec.scrape_logger.info(f'{t}')\n",
    "            sec.scrape_logger.info(f'\\nInstantiated {symbol}...')\n",
    "        except Exception as e:\n",
    "            sec.scrape_logger.info(f'{t}')\n",
    "            sec.scrape_logger.error(f'Failed to instantiate {ticker} with cik {cik}...{e}')\n",
    "            continue\n",
    "\n",
    "        filings = symbol.submissions.pop('filings')\n",
    "        # print(filings)\n",
    "        # Insert submissions to TickerData collection\n",
    "        inserted_submission = mongo.insert_submission(submission=symbol._submissions)\n",
    "        if inserted_submission is not None:\n",
    "            failed_submissions.append(inserted_submission)\n",
    "\n",
    "        # Insert filings to TickerFilings collection\n",
    "        inserted_filing = mongo.insert_filings(cik=cik, filings=filings)\n",
    "        if inserted_filing is not None:\n",
    "            failed_filings.append(inserted_filing)\n",
    "\n",
    "        # # Insert facts to Facts collection\n",
    "        # for doc in filings:\n",
    "        #     doc['lastUpdated'] = dt.datetime.now()\n",
    "\n",
    "        #     if doc['form'] == '10-Q' or doc['form'] == '10-K':\n",
    "        #         try:\n",
    "        #             facts = symbol.get_facts_for_each_filing(doc)\n",
    "        #             inserted_facts = mongo.insert_facts(accession=doc['accessionNumber'], facts=facts)\n",
    "        #             if inserted_facts is not None:\n",
    "        #                 failed_facts.append(inserted_facts)\n",
    "        #         except Exception as e:\n",
    "        #             sec.scrape_logger.error(f'TickerData().get_facts_for_each_filing() function failed for {doc[\"accessionNumber\"]}...{e}')\n",
    "        #             failed_facts.append(doc['accessionNumber'])\n",
    "            \n",
    "        sec.scrape_logger.info(f'Successfully updated {ticker}({cik})...\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather labels, definitions, and calculations xml data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 22:01:23,273 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/files/company_tickers.json\n",
      "2023-10-26 22:01:23,931 - sec-scraper - INFO - Request successful at URL: https://data.sec.gov/submissions/CIK0001326801.json\n",
      "2023-10-26 22:01:24,540 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/index.json\n",
      "Gathering xml-data:   0%|          | 0/45 [00:00<?, ?it/s]2023-10-26 22:01:24,690 - sec-scraper - INFO - 2012-07-31: https://www.sec.gov/Archives/edgar/data/0001326801/000119312512325997\n",
      "Gathering xml-data:   0%|          | 0/45 [00:00<?, ?it/s, accessionNumber=0001193125-12-325997, cik=0001326801, ticker=META]2023-10-26 22:01:24,691 - sec-scraper - INFO - Gathering xml-data:   0%|          | 0/45 [00:00<?, ?it/s, accessionNumber=0001193125-12-325997, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:01:25,445 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000119312512325997/0001193125-12-325997.txt\n",
      "2023-10-26 22:01:27,684 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000119312512325997/0001193125-12-325997.txt successfully.\n",
      "2023-10-26 22:01:27,687 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000119312512325997...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:01:28,555 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000119312512325997/index.json\n",
      "2023-10-26 22:01:29,175 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000119312512325997/fb-20120630_lab.xml\n",
      "2023-10-26 22:01:31,575 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000119312512325997/fb-20120630_cal.xml\n",
      "2023-10-26 22:01:32,120 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000119312512325997/fb-20120630_def.xml\n",
      "2023-10-26 22:01:32,163 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 525...\n",
      "2023-10-26 22:01:32,170 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 525...\n",
      "2023-10-26 22:01:32,171 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000119312512325997...\n",
      "\n",
      "Gathering xml-data:   2%|▏         | 1/45 [00:07<05:29,  7.48s/it, accessionNumber=0001193125-12-325997, cik=0001326801, ticker=META]2023-10-26 22:01:32,172 - sec-scraper - INFO - 2012-10-24: https://www.sec.gov/Archives/edgar/data/0001326801/000132680112000006\n",
      "Gathering xml-data:   2%|▏         | 1/45 [00:07<05:29,  7.48s/it, accessionNumber=0001326801-12-000006, cik=0001326801, ticker=META]2023-10-26 22:01:32,174 - sec-scraper - INFO - Gathering xml-data:   2%|▏         | 1/45 [00:07<05:29,  7.48s/it, accessionNumber=0001326801-12-000006, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:01:32,976 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680112000006/0001326801-12-000006.txt\n",
      "2023-10-26 22:01:34,964 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680112000006/0001326801-12-000006.txt successfully.\n",
      "2023-10-26 22:01:34,966 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680112000006...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:01:35,806 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680112000006/index.json\n",
      "2023-10-26 22:01:36,433 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680112000006/fb-20120930_lab.xml\n",
      "2023-10-26 22:01:36,999 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680112000006/fb-20120930_cal.xml\n",
      "2023-10-26 22:01:37,710 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680112000006/fb-20120930_def.xml\n",
      "2023-10-26 22:01:37,752 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 552...\n",
      "2023-10-26 22:01:37,758 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 552...\n",
      "2023-10-26 22:01:37,767 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680112000006...\n",
      "\n",
      "Gathering xml-data:   4%|▍         | 2/45 [00:13<04:34,  6.37s/it, accessionNumber=0001326801-12-000006, cik=0001326801, ticker=META]2023-10-26 22:01:37,769 - sec-scraper - INFO - 2013-02-01: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000003\n",
      "Gathering xml-data:   4%|▍         | 2/45 [00:13<04:34,  6.37s/it, accessionNumber=0001326801-13-000003, cik=0001326801, ticker=META]2023-10-26 22:01:37,770 - sec-scraper - INFO - Gathering xml-data:   4%|▍         | 2/45 [00:13<04:34,  6.37s/it, accessionNumber=0001326801-13-000003, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:01:38,356 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000003/0001326801-13-000003.txt\n",
      "2023-10-26 22:01:47,787 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000003/0001326801-13-000003.txt successfully.\n",
      "2023-10-26 22:01:47,790 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000003...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:01:49,042 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000003/index.json\n",
      "2023-10-26 22:01:49,817 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000003/fb-20121231_lab.xml\n",
      "2023-10-26 22:01:50,531 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000003/fb-20121231_cal.xml\n",
      "2023-10-26 22:01:51,191 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000003/fb-20121231_def.xml\n",
      "2023-10-26 22:01:51,247 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 1043...\n",
      "2023-10-26 22:01:51,252 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 1043...\n",
      "2023-10-26 22:01:51,269 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000003...\n",
      "\n",
      "Gathering xml-data:   7%|▋         | 3/45 [00:26<06:44,  9.63s/it, accessionNumber=0001326801-13-000003, cik=0001326801, ticker=META]2023-10-26 22:01:51,270 - sec-scraper - INFO - 2013-05-02: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000011\n",
      "Gathering xml-data:   7%|▋         | 3/45 [00:26<06:44,  9.63s/it, accessionNumber=0001326801-13-000011, cik=0001326801, ticker=META]2023-10-26 22:01:51,272 - sec-scraper - INFO - Gathering xml-data:   7%|▋         | 3/45 [00:26<06:44,  9.63s/it, accessionNumber=0001326801-13-000011, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:01:52,227 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000011/0001326801-13-000011.txt\n",
      "2023-10-26 22:01:53,772 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000011/0001326801-13-000011.txt successfully.\n",
      "2023-10-26 22:01:53,774 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000011...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:01:54,574 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000011/index.json\n",
      "2023-10-26 22:01:55,308 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000011/fb-20130331_lab.xml\n",
      "2023-10-26 22:01:55,923 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000011/fb-20130331_cal.xml\n",
      "2023-10-26 22:01:56,484 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000011/fb-20130331_def.xml\n",
      "2023-10-26 22:01:56,522 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 432...\n",
      "2023-10-26 22:01:56,527 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 432...\n",
      "2023-10-26 22:01:56,542 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000011...\n",
      "\n",
      "Gathering xml-data:   9%|▉         | 4/45 [00:31<05:24,  7.91s/it, accessionNumber=0001326801-13-000011, cik=0001326801, ticker=META]2023-10-26 22:01:56,543 - sec-scraper - INFO - 2013-07-25: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000019\n",
      "Gathering xml-data:   9%|▉         | 4/45 [00:31<05:24,  7.91s/it, accessionNumber=0001326801-13-000019, cik=0001326801, ticker=META]2023-10-26 22:01:56,544 - sec-scraper - INFO - Gathering xml-data:   9%|▉         | 4/45 [00:31<05:24,  7.91s/it, accessionNumber=0001326801-13-000019, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:01:57,624 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000019/0001326801-13-000019.txt\n",
      "2023-10-26 22:02:02,646 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000019/0001326801-13-000019.txt successfully.\n",
      "2023-10-26 22:02:02,648 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000019...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:02:03,729 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000019/index.json\n",
      "2023-10-26 22:02:04,302 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000019/fb-20130630_lab.xml\n",
      "2023-10-26 22:02:04,886 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000019/fb-20130630_cal.xml\n",
      "2023-10-26 22:02:05,512 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000019/fb-20130630_def.xml\n",
      "2023-10-26 22:02:05,551 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 571...\n",
      "2023-10-26 22:02:05,556 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 571...\n",
      "2023-10-26 22:02:05,573 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000019...\n",
      "\n",
      "Gathering xml-data:  11%|█         | 5/45 [00:40<05:32,  8.31s/it, accessionNumber=0001326801-13-000019, cik=0001326801, ticker=META]2023-10-26 22:02:05,575 - sec-scraper - INFO - 2013-11-01: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000031\n",
      "Gathering xml-data:  11%|█         | 5/45 [00:40<05:32,  8.31s/it, accessionNumber=0001326801-13-000031, cik=0001326801, ticker=META]2023-10-26 22:02:05,576 - sec-scraper - INFO - Gathering xml-data:  11%|█         | 5/45 [00:40<05:32,  8.31s/it, accessionNumber=0001326801-13-000031, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:02:06,390 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000031/0001326801-13-000031.txt\n",
      "2023-10-26 22:02:09,581 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000031/0001326801-13-000031.txt successfully.\n",
      "2023-10-26 22:02:09,583 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000031...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:02:10,603 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000031/index.json\n",
      "2023-10-26 22:02:11,236 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000031/fb-20130930_lab.xml\n",
      "2023-10-26 22:02:11,841 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000031/fb-20130930_cal.xml\n",
      "2023-10-26 22:02:12,400 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000031/fb-20130930_def.xml\n",
      "2023-10-26 22:02:12,444 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 563...\n",
      "2023-10-26 22:02:12,448 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 563...\n",
      "2023-10-26 22:02:12,470 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680113000031...\n",
      "\n",
      "Gathering xml-data:  13%|█▎        | 6/45 [00:47<05:05,  7.83s/it, accessionNumber=0001326801-13-000031, cik=0001326801, ticker=META]2023-10-26 22:02:12,470 - sec-scraper - INFO - 2014-01-31: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000007\n",
      "Gathering xml-data:  13%|█▎        | 6/45 [00:47<05:05,  7.83s/it, accessionNumber=0001326801-14-000007, cik=0001326801, ticker=META]2023-10-26 22:02:12,471 - sec-scraper - INFO - Gathering xml-data:  13%|█▎        | 6/45 [00:47<05:05,  7.83s/it, accessionNumber=0001326801-14-000007, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:02:13,009 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000007/0001326801-14-000007.txt\n",
      "2023-10-26 22:02:15,523 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000007/0001326801-14-000007.txt successfully.\n",
      "2023-10-26 22:02:15,526 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000007...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:02:16,620 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000007/index.json\n",
      "2023-10-26 22:02:17,224 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000007/fb-20131231_lab.xml\n",
      "2023-10-26 22:02:17,914 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000007/fb-20131231_cal.xml\n",
      "2023-10-26 22:02:19,419 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000007/fb-20131231_def.xml\n",
      "2023-10-26 22:02:19,479 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 957...\n",
      "2023-10-26 22:02:19,484 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 957...\n",
      "2023-10-26 22:02:19,509 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000007...\n",
      "\n",
      "Gathering xml-data:  16%|█▌        | 7/45 [00:54<04:47,  7.57s/it, accessionNumber=0001326801-14-000007, cik=0001326801, ticker=META]2023-10-26 22:02:19,511 - sec-scraper - INFO - 2014-04-25: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000023\n",
      "Gathering xml-data:  16%|█▌        | 7/45 [00:54<04:47,  7.57s/it, accessionNumber=0001326801-14-000023, cik=0001326801, ticker=META]2023-10-26 22:02:19,512 - sec-scraper - INFO - Gathering xml-data:  16%|█▌        | 7/45 [00:54<04:47,  7.57s/it, accessionNumber=0001326801-14-000023, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:02:20,279 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000023/0001326801-14-000023.txt\n",
      "2023-10-26 22:02:26,707 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000023/0001326801-14-000023.txt successfully.\n",
      "2023-10-26 22:02:26,709 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000023...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:02:27,571 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000023/index.json\n",
      "2023-10-26 22:02:28,109 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000023/fb-20140331_lab.xml\n",
      "2023-10-26 22:02:28,763 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000023/fb-20140331_cal.xml\n",
      "2023-10-26 22:02:29,355 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000023/fb-20140331_def.xml\n",
      "2023-10-26 22:02:29,404 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 406...\n",
      "2023-10-26 22:02:29,409 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 406...\n",
      "2023-10-26 22:02:29,433 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000023...\n",
      "\n",
      "Gathering xml-data:  18%|█▊        | 8/45 [01:04<05:07,  8.32s/it, accessionNumber=0001326801-14-000023, cik=0001326801, ticker=META]2023-10-26 22:02:29,434 - sec-scraper - INFO - 2014-07-24: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000032\n",
      "Gathering xml-data:  18%|█▊        | 8/45 [01:04<05:07,  8.32s/it, accessionNumber=0001326801-14-000032, cik=0001326801, ticker=META]2023-10-26 22:02:29,434 - sec-scraper - INFO - Gathering xml-data:  18%|█▊        | 8/45 [01:04<05:07,  8.32s/it, accessionNumber=0001326801-14-000032, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:02:30,144 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000032/0001326801-14-000032.txt\n",
      "2023-10-26 22:02:34,791 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000032/0001326801-14-000032.txt successfully.\n",
      "2023-10-26 22:02:34,793 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000032...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:02:35,640 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000032/index.json\n",
      "2023-10-26 22:02:36,257 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000032/fb-20140630_lab.xml\n",
      "2023-10-26 22:02:36,811 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000032/fb-20140630_cal.xml\n",
      "2023-10-26 22:02:37,474 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000032/fb-20140630_def.xml\n",
      "2023-10-26 22:02:37,519 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 538...\n",
      "2023-10-26 22:02:37,524 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 538...\n",
      "2023-10-26 22:02:37,552 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000032...\n",
      "\n",
      "Gathering xml-data:  20%|██        | 9/45 [01:12<04:57,  8.26s/it, accessionNumber=0001326801-14-000032, cik=0001326801, ticker=META]2023-10-26 22:02:37,553 - sec-scraper - INFO - 2014-10-30: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000068\n",
      "Gathering xml-data:  20%|██        | 9/45 [01:12<04:57,  8.26s/it, accessionNumber=0001326801-14-000068, cik=0001326801, ticker=META]2023-10-26 22:02:37,554 - sec-scraper - INFO - Gathering xml-data:  20%|██        | 9/45 [01:12<04:57,  8.26s/it, accessionNumber=0001326801-14-000068, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:02:38,299 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000068/0001326801-14-000068.txt\n",
      "2023-10-26 22:02:43,224 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000068/0001326801-14-000068.txt successfully.\n",
      "2023-10-26 22:02:43,226 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000068...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:02:44,166 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000068/index.json\n",
      "2023-10-26 22:02:44,801 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000068/fb-20140930_lab.xml\n",
      "2023-10-26 22:02:45,562 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000068/fb-20140930_cal.xml\n",
      "2023-10-26 22:02:46,143 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000068/fb-20140930_def.xml\n",
      "2023-10-26 22:02:46,198 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 614...\n",
      "2023-10-26 22:02:46,203 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 614...\n",
      "2023-10-26 22:02:46,233 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680114000068...\n",
      "\n",
      "Gathering xml-data:  22%|██▏       | 10/45 [01:21<04:53,  8.39s/it, accessionNumber=0001326801-14-000068, cik=0001326801, ticker=META]2023-10-26 22:02:46,234 - sec-scraper - INFO - 2015-01-29: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000006\n",
      "Gathering xml-data:  22%|██▏       | 10/45 [01:21<04:53,  8.39s/it, accessionNumber=0001326801-15-000006, cik=0001326801, ticker=META]2023-10-26 22:02:46,236 - sec-scraper - INFO - Gathering xml-data:  22%|██▏       | 10/45 [01:21<04:53,  8.39s/it, accessionNumber=0001326801-15-000006, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:02:46,769 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000006/0001326801-15-000006.txt\n",
      "2023-10-26 22:02:51,512 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000006/0001326801-15-000006.txt successfully.\n",
      "2023-10-26 22:02:51,514 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000006...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:02:52,666 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000006/index.json\n",
      "2023-10-26 22:02:53,279 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000006/fb-20141231_lab.xml\n",
      "2023-10-26 22:02:54,086 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000006/fb-20141231_cal.xml\n",
      "2023-10-26 22:02:54,700 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000006/fb-20141231_def.xml\n",
      "2023-10-26 22:02:54,770 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 990...\n",
      "2023-10-26 22:02:54,776 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 990...\n",
      "2023-10-26 22:02:54,811 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000006...\n",
      "\n",
      "Gathering xml-data:  24%|██▍       | 11/45 [01:30<04:47,  8.45s/it, accessionNumber=0001326801-15-000006, cik=0001326801, ticker=META]2023-10-26 22:02:54,813 - sec-scraper - INFO - 2015-04-23: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000015\n",
      "Gathering xml-data:  24%|██▍       | 11/45 [01:30<04:47,  8.45s/it, accessionNumber=0001326801-15-000015, cik=0001326801, ticker=META]2023-10-26 22:02:54,814 - sec-scraper - INFO - Gathering xml-data:  24%|██▍       | 11/45 [01:30<04:47,  8.45s/it, accessionNumber=0001326801-15-000015, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:02:55,652 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000015/0001326801-15-000015.txt\n",
      "2023-10-26 22:02:58,386 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000015/0001326801-15-000015.txt successfully.\n",
      "2023-10-26 22:02:58,388 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000015...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:02:59,257 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000015/index.json\n",
      "2023-10-26 22:02:59,906 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000015/fb-20150331_lab.xml\n",
      "2023-10-26 22:03:00,551 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000015/fb-20150331_cal.xml\n",
      "2023-10-26 22:03:01,150 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000015/fb-20150331_def.xml\n",
      "2023-10-26 22:03:01,204 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 459...\n",
      "2023-10-26 22:03:01,209 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 459...\n",
      "2023-10-26 22:03:01,243 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000015...\n",
      "\n",
      "Gathering xml-data:  27%|██▋       | 12/45 [01:36<04:18,  7.83s/it, accessionNumber=0001326801-15-000015, cik=0001326801, ticker=META]2023-10-26 22:03:01,244 - sec-scraper - INFO - 2015-07-31: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000028\n",
      "Gathering xml-data:  27%|██▋       | 12/45 [01:36<04:18,  7.83s/it, accessionNumber=0001326801-15-000028, cik=0001326801, ticker=META]2023-10-26 22:03:01,245 - sec-scraper - INFO - Gathering xml-data:  27%|██▋       | 12/45 [01:36<04:18,  7.83s/it, accessionNumber=0001326801-15-000028, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:03:02,234 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000028/0001326801-15-000028.txt\n",
      "2023-10-26 22:03:05,360 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000028/0001326801-15-000028.txt successfully.\n",
      "2023-10-26 22:03:05,362 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000028...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:03:06,161 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000028/index.json\n",
      "2023-10-26 22:03:06,773 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000028/fb-20150630_lab.xml\n",
      "2023-10-26 22:03:07,378 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000028/fb-20150630_cal.xml\n",
      "2023-10-26 22:03:08,044 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000028/fb-20150630_def.xml\n",
      "2023-10-26 22:03:08,092 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 565...\n",
      "2023-10-26 22:03:08,097 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 565...\n",
      "2023-10-26 22:03:08,135 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000028...\n",
      "\n",
      "Gathering xml-data:  29%|██▉       | 13/45 [01:43<04:01,  7.55s/it, accessionNumber=0001326801-15-000028, cik=0001326801, ticker=META]2023-10-26 22:03:08,136 - sec-scraper - INFO - 2015-11-05: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000032\n",
      "Gathering xml-data:  29%|██▉       | 13/45 [01:43<04:01,  7.55s/it, accessionNumber=0001326801-15-000032, cik=0001326801, ticker=META]2023-10-26 22:03:08,137 - sec-scraper - INFO - Gathering xml-data:  29%|██▉       | 13/45 [01:43<04:01,  7.55s/it, accessionNumber=0001326801-15-000032, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:03:08,886 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000032/0001326801-15-000032.txt\n",
      "2023-10-26 22:03:12,375 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000032/0001326801-15-000032.txt successfully.\n",
      "2023-10-26 22:03:12,377 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000032...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:03:13,197 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000032/index.json\n",
      "2023-10-26 22:03:13,885 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000032/fb-20150930_lab.xml\n",
      "2023-10-26 22:03:14,683 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000032/fb-20150930_cal.xml\n",
      "2023-10-26 22:03:15,254 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000032/fb-20150930_def.xml\n",
      "2023-10-26 22:03:15,302 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 565...\n",
      "2023-10-26 22:03:15,308 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 565...\n",
      "2023-10-26 22:03:15,351 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680115000032...\n",
      "\n",
      "Gathering xml-data:  31%|███       | 14/45 [01:50<03:50,  7.45s/it, accessionNumber=0001326801-15-000032, cik=0001326801, ticker=META]2023-10-26 22:03:15,353 - sec-scraper - INFO - 2016-01-28: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000043\n",
      "Gathering xml-data:  31%|███       | 14/45 [01:50<03:50,  7.45s/it, accessionNumber=0001326801-16-000043, cik=0001326801, ticker=META]2023-10-26 22:03:15,354 - sec-scraper - INFO - Gathering xml-data:  31%|███       | 14/45 [01:50<03:50,  7.45s/it, accessionNumber=0001326801-16-000043, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:03:15,896 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000043/0001326801-16-000043.txt\n",
      "2023-10-26 22:03:18,998 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000043/0001326801-16-000043.txt successfully.\n",
      "2023-10-26 22:03:19,000 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000043...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:03:20,013 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000043/index.json\n",
      "2023-10-26 22:03:20,817 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000043/fb-20151231_lab.xml\n",
      "2023-10-26 22:03:21,548 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000043/fb-20151231_cal.xml\n",
      "2023-10-26 22:03:22,245 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000043/fb-20151231_def.xml\n",
      "2023-10-26 22:03:22,308 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 922...\n",
      "2023-10-26 22:03:22,313 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 922...\n",
      "2023-10-26 22:03:22,358 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000043...\n",
      "\n",
      "Gathering xml-data:  33%|███▎      | 15/45 [01:57<03:39,  7.32s/it, accessionNumber=0001326801-16-000043, cik=0001326801, ticker=META]2023-10-26 22:03:22,359 - sec-scraper - INFO - 2016-04-28: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000067\n",
      "Gathering xml-data:  33%|███▎      | 15/45 [01:57<03:39,  7.32s/it, accessionNumber=0001326801-16-000067, cik=0001326801, ticker=META]2023-10-26 22:03:22,361 - sec-scraper - INFO - Gathering xml-data:  33%|███▎      | 15/45 [01:57<03:39,  7.32s/it, accessionNumber=0001326801-16-000067, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:03:23,176 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000067/0001326801-16-000067.txt\n",
      "2023-10-26 22:03:25,927 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000067/0001326801-16-000067.txt successfully.\n",
      "2023-10-26 22:03:25,929 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000067...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:03:26,731 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000067/index.json\n",
      "2023-10-26 22:03:27,336 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000067/fb-20160331_lab.xml\n",
      "2023-10-26 22:03:28,034 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000067/fb-20160331_cal.xml\n",
      "2023-10-26 22:03:28,680 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000067/fb-20160331_def.xml\n",
      "2023-10-26 22:03:28,729 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 455...\n",
      "2023-10-26 22:03:28,734 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 455...\n",
      "2023-10-26 22:03:28,777 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000067...\n",
      "\n",
      "Gathering xml-data:  36%|███▌      | 16/45 [02:04<03:24,  7.05s/it, accessionNumber=0001326801-16-000067, cik=0001326801, ticker=META]2023-10-26 22:03:28,779 - sec-scraper - INFO - 2016-07-28: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000082\n",
      "Gathering xml-data:  36%|███▌      | 16/45 [02:04<03:24,  7.05s/it, accessionNumber=0001326801-16-000082, cik=0001326801, ticker=META]2023-10-26 22:03:28,780 - sec-scraper - INFO - Gathering xml-data:  36%|███▌      | 16/45 [02:04<03:24,  7.05s/it, accessionNumber=0001326801-16-000082, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:03:29,746 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000082/0001326801-16-000082.txt\n",
      "2023-10-26 22:03:31,850 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000082/0001326801-16-000082.txt successfully.\n",
      "2023-10-26 22:03:31,852 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000082...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:03:32,651 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000082/index.json\n",
      "2023-10-26 22:03:33,328 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000082/fb-20160630_lab.xml\n",
      "2023-10-26 22:03:33,938 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000082/fb-20160630_cal.xml\n",
      "2023-10-26 22:03:34,560 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000082/fb-20160630_def.xml\n",
      "2023-10-26 22:03:34,609 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 574...\n",
      "2023-10-26 22:03:34,614 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 574...\n",
      "2023-10-26 22:03:34,661 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000082...\n",
      "\n",
      "Gathering xml-data:  38%|███▊      | 17/45 [02:09<03:07,  6.70s/it, accessionNumber=0001326801-16-000082, cik=0001326801, ticker=META]2023-10-26 22:03:34,662 - sec-scraper - INFO - 2016-11-03: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000087\n",
      "Gathering xml-data:  38%|███▊      | 17/45 [02:09<03:07,  6.70s/it, accessionNumber=0001326801-16-000087, cik=0001326801, ticker=META]2023-10-26 22:03:34,663 - sec-scraper - INFO - Gathering xml-data:  38%|███▊      | 17/45 [02:09<03:07,  6.70s/it, accessionNumber=0001326801-16-000087, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:03:35,681 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000087/0001326801-16-000087.txt\n",
      "2023-10-26 22:03:36,727 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000087/0001326801-16-000087.txt successfully.\n",
      "2023-10-26 22:03:36,730 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000087...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:03:37,572 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000087/index.json\n",
      "2023-10-26 22:03:38,204 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000087/fb-20160930_lab.xml\n",
      "2023-10-26 22:03:39,052 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000087/fb-20160930_cal.xml\n",
      "2023-10-26 22:03:39,645 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000087/fb-20160930_def.xml\n",
      "2023-10-26 22:03:39,697 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 566...\n",
      "2023-10-26 22:03:39,703 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 566...\n",
      "2023-10-26 22:03:39,753 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680116000087...\n",
      "\n",
      "Gathering xml-data:  40%|████      | 18/45 [02:15<02:47,  6.21s/it, accessionNumber=0001326801-16-000087, cik=0001326801, ticker=META]2023-10-26 22:03:39,755 - sec-scraper - INFO - 2017-02-03: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000007\n",
      "Gathering xml-data:  40%|████      | 18/45 [02:15<02:47,  6.21s/it, accessionNumber=0001326801-17-000007, cik=0001326801, ticker=META]2023-10-26 22:03:39,756 - sec-scraper - INFO - Gathering xml-data:  40%|████      | 18/45 [02:15<02:47,  6.21s/it, accessionNumber=0001326801-17-000007, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:03:40,316 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000007/0001326801-17-000007.txt\n",
      "2023-10-26 22:03:46,285 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000007/0001326801-17-000007.txt successfully.\n",
      "2023-10-26 22:03:46,287 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000007...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:03:47,333 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000007/index.json\n",
      "2023-10-26 22:03:47,984 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000007/fb-20161231_lab.xml\n",
      "2023-10-26 22:03:48,820 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000007/fb-20161231_cal.xml\n",
      "2023-10-26 22:03:49,476 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000007/fb-20161231_def.xml\n",
      "2023-10-26 22:03:49,539 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 959...\n",
      "2023-10-26 22:03:49,544 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 959...\n",
      "2023-10-26 22:03:49,601 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000007...\n",
      "\n",
      "Gathering xml-data:  42%|████▏     | 19/45 [02:24<03:09,  7.31s/it, accessionNumber=0001326801-17-000007, cik=0001326801, ticker=META]2023-10-26 22:03:49,603 - sec-scraper - INFO - 2017-05-04: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000024\n",
      "Gathering xml-data:  42%|████▏     | 19/45 [02:24<03:09,  7.31s/it, accessionNumber=0001326801-17-000024, cik=0001326801, ticker=META]2023-10-26 22:03:49,604 - sec-scraper - INFO - Gathering xml-data:  42%|████▏     | 19/45 [02:24<03:09,  7.31s/it, accessionNumber=0001326801-17-000024, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:03:50,363 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000024/0001326801-17-000024.txt\n",
      "2023-10-26 22:03:52,597 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000024/0001326801-17-000024.txt successfully.\n",
      "2023-10-26 22:03:52,599 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000024...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:03:53,339 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000024/index.json\n",
      "2023-10-26 22:03:53,983 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000024/fb-20170331_lab.xml\n",
      "2023-10-26 22:03:54,722 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000024/fb-20170331_cal.xml\n",
      "2023-10-26 22:03:55,333 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000024/fb-20170331_def.xml\n",
      "2023-10-26 22:03:55,386 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 448...\n",
      "2023-10-26 22:03:55,391 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 448...\n",
      "2023-10-26 22:03:55,445 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000024...\n",
      "\n",
      "Gathering xml-data:  44%|████▍     | 20/45 [02:30<02:51,  6.87s/it, accessionNumber=0001326801-17-000024, cik=0001326801, ticker=META]2023-10-26 22:03:55,447 - sec-scraper - INFO - 2017-07-27: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000038\n",
      "Gathering xml-data:  44%|████▍     | 20/45 [02:30<02:51,  6.87s/it, accessionNumber=0001326801-17-000038, cik=0001326801, ticker=META]2023-10-26 22:03:55,448 - sec-scraper - INFO - Gathering xml-data:  44%|████▍     | 20/45 [02:30<02:51,  6.87s/it, accessionNumber=0001326801-17-000038, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:03:56,288 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000038/0001326801-17-000038.txt\n",
      "2023-10-26 22:03:57,221 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000038/0001326801-17-000038.txt successfully.\n",
      "2023-10-26 22:03:57,223 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000038...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:03:58,002 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000038/index.json\n",
      "2023-10-26 22:03:58,640 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000038/fb-20170630_lab.xml\n",
      "2023-10-26 22:03:59,420 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000038/fb-20170630_cal.xml\n",
      "2023-10-26 22:04:00,027 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000038/fb-20170630_def.xml\n",
      "2023-10-26 22:04:00,082 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 548...\n",
      "2023-10-26 22:04:00,087 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 548...\n",
      "2023-10-26 22:04:00,146 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000038...\n",
      "\n",
      "Gathering xml-data:  47%|████▋     | 21/45 [02:35<02:29,  6.22s/it, accessionNumber=0001326801-17-000038, cik=0001326801, ticker=META]2023-10-26 22:04:00,148 - sec-scraper - INFO - 2017-11-02: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000053\n",
      "Gathering xml-data:  47%|████▋     | 21/45 [02:35<02:29,  6.22s/it, accessionNumber=0001326801-17-000053, cik=0001326801, ticker=META]2023-10-26 22:04:00,149 - sec-scraper - INFO - Gathering xml-data:  47%|████▋     | 21/45 [02:35<02:29,  6.22s/it, accessionNumber=0001326801-17-000053, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:04:00,960 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000053/0001326801-17-000053.txt\n",
      "2023-10-26 22:04:01,863 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000053/0001326801-17-000053.txt successfully.\n",
      "2023-10-26 22:04:01,865 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000053...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:04:02,616 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000053/index.json\n",
      "2023-10-26 22:04:03,231 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000053/fb-20170930_lab.xml\n",
      "2023-10-26 22:04:04,006 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000053/fb-20170930_cal.xml\n",
      "2023-10-26 22:04:04,686 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000053/fb-20170930_def.xml\n",
      "2023-10-26 22:04:04,741 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 542...\n",
      "2023-10-26 22:04:04,746 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 542...\n",
      "2023-10-26 22:04:04,808 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680117000053...\n",
      "\n",
      "Gathering xml-data:  49%|████▉     | 22/45 [02:40<02:12,  5.75s/it, accessionNumber=0001326801-17-000053, cik=0001326801, ticker=META]2023-10-26 22:04:04,809 - sec-scraper - INFO - 2018-02-01: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000009\n",
      "Gathering xml-data:  49%|████▉     | 22/45 [02:40<02:12,  5.75s/it, accessionNumber=0001326801-18-000009, cik=0001326801, ticker=META]2023-10-26 22:04:04,810 - sec-scraper - INFO - Gathering xml-data:  49%|████▉     | 22/45 [02:40<02:12,  5.75s/it, accessionNumber=0001326801-18-000009, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:04:05,774 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000009/0001326801-18-000009.txt\n",
      "2023-10-26 22:04:09,992 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000009/0001326801-18-000009.txt successfully.\n",
      "2023-10-26 22:04:09,994 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000009...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:04:11,001 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000009/index.json\n",
      "2023-10-26 22:04:11,676 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000009/fb-20171231_lab.xml\n",
      "2023-10-26 22:04:12,473 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000009/fb-20171231_cal.xml\n",
      "2023-10-26 22:04:13,102 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000009/fb-20171231_def.xml\n",
      "2023-10-26 22:04:13,167 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 823...\n",
      "2023-10-26 22:04:13,172 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 823...\n",
      "2023-10-26 22:04:13,236 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000009...\n",
      "\n",
      "Gathering xml-data:  51%|█████     | 23/45 [02:48<02:24,  6.55s/it, accessionNumber=0001326801-18-000009, cik=0001326801, ticker=META]2023-10-26 22:04:13,237 - sec-scraper - INFO - 2018-04-26: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000032\n",
      "Gathering xml-data:  51%|█████     | 23/45 [02:48<02:24,  6.55s/it, accessionNumber=0001326801-18-000032, cik=0001326801, ticker=META]2023-10-26 22:04:13,238 - sec-scraper - INFO - Gathering xml-data:  51%|█████     | 23/45 [02:48<02:24,  6.55s/it, accessionNumber=0001326801-18-000032, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:04:14,244 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000032/0001326801-18-000032.txt\n",
      "2023-10-26 22:04:15,208 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000032/0001326801-18-000032.txt successfully.\n",
      "2023-10-26 22:04:15,210 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000032...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:04:16,004 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000032/index.json\n",
      "2023-10-26 22:04:16,622 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000032/fb-20180331_lab.xml\n",
      "2023-10-26 22:04:17,399 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000032/fb-20180331_cal.xml\n",
      "2023-10-26 22:04:18,019 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000032/fb-20180331_def.xml\n",
      "2023-10-26 22:04:18,085 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 480...\n",
      "2023-10-26 22:04:18,090 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 480...\n",
      "2023-10-26 22:04:18,154 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000032...\n",
      "\n",
      "Gathering xml-data:  53%|█████▎    | 24/45 [02:53<02:07,  6.06s/it, accessionNumber=0001326801-18-000032, cik=0001326801, ticker=META]2023-10-26 22:04:18,155 - sec-scraper - INFO - 2018-07-26: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000057\n",
      "Gathering xml-data:  53%|█████▎    | 24/45 [02:53<02:07,  6.06s/it, accessionNumber=0001326801-18-000057, cik=0001326801, ticker=META]2023-10-26 22:04:18,157 - sec-scraper - INFO - Gathering xml-data:  53%|█████▎    | 24/45 [02:53<02:07,  6.06s/it, accessionNumber=0001326801-18-000057, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:04:18,965 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000057/0001326801-18-000057.txt\n",
      "2023-10-26 22:04:23,730 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000057/0001326801-18-000057.txt successfully.\n",
      "2023-10-26 22:04:23,732 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000057...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:04:24,650 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000057/index.json\n",
      "2023-10-26 22:04:25,387 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000057/fb-20180630_lab.xml\n",
      "2023-10-26 22:04:26,176 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000057/fb-20180630_cal.xml\n",
      "2023-10-26 22:04:26,814 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000057/fb-20180630_def.xml\n",
      "2023-10-26 22:04:26,878 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 598...\n",
      "2023-10-26 22:04:26,883 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 598...\n",
      "2023-10-26 22:04:26,950 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000057...\n",
      "\n",
      "Gathering xml-data:  56%|█████▌    | 25/45 [03:02<02:17,  6.88s/it, accessionNumber=0001326801-18-000057, cik=0001326801, ticker=META]2023-10-26 22:04:26,952 - sec-scraper - INFO - 2018-10-31: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000067\n",
      "Gathering xml-data:  56%|█████▌    | 25/45 [03:02<02:17,  6.88s/it, accessionNumber=0001326801-18-000067, cik=0001326801, ticker=META]2023-10-26 22:04:26,953 - sec-scraper - INFO - Gathering xml-data:  56%|█████▌    | 25/45 [03:02<02:17,  6.88s/it, accessionNumber=0001326801-18-000067, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:04:27,799 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000067/0001326801-18-000067.txt\n",
      "2023-10-26 22:04:29,486 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000067/0001326801-18-000067.txt successfully.\n",
      "2023-10-26 22:04:29,488 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000067...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:04:30,296 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000067/index.json\n",
      "2023-10-26 22:04:30,896 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000067/fb-20180930_lab.xml\n",
      "2023-10-26 22:04:31,604 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000067/fb-20180930_cal.xml\n",
      "2023-10-26 22:04:32,272 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000067/fb-20180930_def.xml\n",
      "2023-10-26 22:04:32,334 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 695...\n",
      "2023-10-26 22:04:32,340 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 695...\n",
      "2023-10-26 22:04:32,412 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680118000067...\n",
      "\n",
      "Gathering xml-data:  58%|█████▊    | 26/45 [03:07<02:02,  6.46s/it, accessionNumber=0001326801-18-000067, cik=0001326801, ticker=META]2023-10-26 22:04:32,413 - sec-scraper - INFO - 2019-01-31: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000009\n",
      "Gathering xml-data:  58%|█████▊    | 26/45 [03:07<02:02,  6.46s/it, accessionNumber=0001326801-19-000009, cik=0001326801, ticker=META]2023-10-26 22:04:32,414 - sec-scraper - INFO - Gathering xml-data:  58%|█████▊    | 26/45 [03:07<02:02,  6.46s/it, accessionNumber=0001326801-19-000009, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:04:32,927 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000009/0001326801-19-000009.txt\n",
      "2023-10-26 22:04:35,863 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000009/0001326801-19-000009.txt successfully.\n",
      "2023-10-26 22:04:35,866 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000009...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:04:36,767 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000009/index.json\n",
      "2023-10-26 22:04:37,448 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000009/fb-20181231_lab.xml\n",
      "2023-10-26 22:04:38,152 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000009/fb-20181231_cal.xml\n",
      "2023-10-26 22:04:38,760 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000009/fb-20181231_def.xml\n",
      "2023-10-26 22:04:38,831 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 819...\n",
      "2023-10-26 22:04:38,836 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 819...\n",
      "2023-10-26 22:04:38,909 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000009...\n",
      "\n",
      "Gathering xml-data:  60%|██████    | 27/45 [03:14<01:56,  6.47s/it, accessionNumber=0001326801-19-000009, cik=0001326801, ticker=META]2023-10-26 22:04:38,910 - sec-scraper - INFO - 2019-04-25: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000037\n",
      "Gathering xml-data:  60%|██████    | 27/45 [03:14<01:56,  6.47s/it, accessionNumber=0001326801-19-000037, cik=0001326801, ticker=META]2023-10-26 22:04:38,911 - sec-scraper - INFO - Gathering xml-data:  60%|██████    | 27/45 [03:14<01:56,  6.47s/it, accessionNumber=0001326801-19-000037, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:04:39,808 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000037/0001326801-19-000037.txt\n",
      "2023-10-26 22:04:41,868 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000037/0001326801-19-000037.txt successfully.\n",
      "2023-10-26 22:04:41,871 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000037...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:04:42,697 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000037/index.json\n",
      "2023-10-26 22:04:43,372 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000037/fb-20190331_lab.xml\n",
      "2023-10-26 22:04:44,260 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000037/fb-20190331_cal.xml\n",
      "2023-10-26 22:04:45,163 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000037/fb-20190331_def.xml\n",
      "2023-10-26 22:04:45,229 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 564...\n",
      "2023-10-26 22:04:45,235 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 564...\n",
      "2023-10-26 22:04:45,316 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000037...\n",
      "\n",
      "Gathering xml-data:  62%|██████▏   | 28/45 [03:20<01:49,  6.45s/it, accessionNumber=0001326801-19-000037, cik=0001326801, ticker=META]2023-10-26 22:04:45,318 - sec-scraper - INFO - 2019-07-25: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000055\n",
      "Gathering xml-data:  62%|██████▏   | 28/45 [03:20<01:49,  6.45s/it, accessionNumber=0001326801-19-000055, cik=0001326801, ticker=META]2023-10-26 22:04:45,319 - sec-scraper - INFO - Gathering xml-data:  62%|██████▏   | 28/45 [03:20<01:49,  6.45s/it, accessionNumber=0001326801-19-000055, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:04:46,258 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000055/0001326801-19-000055.txt\n",
      "2023-10-26 22:04:50,342 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000055/0001326801-19-000055.txt successfully.\n",
      "2023-10-26 22:04:50,345 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000055...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:04:51,926 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000055/index.json\n",
      "2023-10-26 22:04:52,589 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000055/fb-20190630_lab.xml\n",
      "2023-10-26 22:04:53,530 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000055/fb-20190630_cal.xml\n",
      "2023-10-26 22:04:54,205 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000055/fb-20190630_def.xml\n",
      "2023-10-26 22:04:54,271 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 773...\n",
      "2023-10-26 22:04:54,277 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 773...\n",
      "2023-10-26 22:04:54,358 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000055...\n",
      "\n",
      "Gathering xml-data:  64%|██████▍   | 29/45 [03:29<01:55,  7.23s/it, accessionNumber=0001326801-19-000055, cik=0001326801, ticker=META]2023-10-26 22:04:54,359 - sec-scraper - INFO - 2019-10-31: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000069\n",
      "Gathering xml-data:  64%|██████▍   | 29/45 [03:29<01:55,  7.23s/it, accessionNumber=0001326801-19-000069, cik=0001326801, ticker=META]2023-10-26 22:04:54,360 - sec-scraper - INFO - Gathering xml-data:  64%|██████▍   | 29/45 [03:29<01:55,  7.23s/it, accessionNumber=0001326801-19-000069, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:04:55,345 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000069/0001326801-19-000069.txt\n",
      "2023-10-26 22:04:59,418 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000069/0001326801-19-000069.txt successfully.\n",
      "2023-10-26 22:04:59,420 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000069...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:04:59,804 - sec-scraper - ERROR - Failed to scrape context for https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000069...list index out of range\n",
      "2023-10-26 22:05:00,261 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000069/index.json\n",
      "2023-10-26 22:05:01,520 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000069/fb-20190930_lab.xml\n",
      "2023-10-26 22:05:02,368 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000069/fb-20190930_cal.xml\n",
      "2023-10-26 22:05:03,035 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000069/fb-20190930_def.xml\n",
      "2023-10-26 22:05:03,103 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 782...\n",
      "2023-10-26 22:05:03,109 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 782...\n",
      "2023-10-26 22:05:03,194 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680119000069...\n",
      "\n",
      "Gathering xml-data:  67%|██████▋   | 30/45 [03:38<01:55,  7.71s/it, accessionNumber=0001326801-19-000069, cik=0001326801, ticker=META]2023-10-26 22:05:03,196 - sec-scraper - INFO - 2020-01-30: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000013\n",
      "Gathering xml-data:  67%|██████▋   | 30/45 [03:38<01:55,  7.71s/it, accessionNumber=0001326801-20-000013, cik=0001326801, ticker=META]2023-10-26 22:05:03,196 - sec-scraper - INFO - Gathering xml-data:  67%|██████▋   | 30/45 [03:38<01:55,  7.71s/it, accessionNumber=0001326801-20-000013, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:05:04,468 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000013/0001326801-20-000013.txt\n",
      "2023-10-26 22:05:09,770 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000013/0001326801-20-000013.txt successfully.\n",
      "2023-10-26 22:05:09,773 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000013...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:05:10,844 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000013/index.json\n",
      "2023-10-26 22:05:11,589 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000013/fb-20191231_lab.xml\n",
      "2023-10-26 22:05:12,366 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000013/fb-20191231_cal.xml\n",
      "2023-10-26 22:05:12,990 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000013/fb-20191231_def.xml\n",
      "2023-10-26 22:05:13,069 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 935...\n",
      "2023-10-26 22:05:13,075 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 935...\n",
      "2023-10-26 22:05:13,162 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000013...\n",
      "\n",
      "Gathering xml-data:  69%|██████▉   | 31/45 [03:48<01:57,  8.39s/it, accessionNumber=0001326801-20-000013, cik=0001326801, ticker=META]2023-10-26 22:05:13,164 - sec-scraper - INFO - 2020-04-30: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000048\n",
      "Gathering xml-data:  69%|██████▉   | 31/45 [03:48<01:57,  8.39s/it, accessionNumber=0001326801-20-000048, cik=0001326801, ticker=META]2023-10-26 22:05:13,165 - sec-scraper - INFO - Gathering xml-data:  69%|██████▉   | 31/45 [03:48<01:57,  8.39s/it, accessionNumber=0001326801-20-000048, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:05:14,174 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000048/0001326801-20-000048.txt\n",
      "2023-10-26 22:05:17,452 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000048/0001326801-20-000048.txt successfully.\n",
      "2023-10-26 22:05:17,454 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000048...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:05:18,339 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000048/index.json\n",
      "2023-10-26 22:05:19,078 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000048/fb-20200331_lab.xml\n",
      "2023-10-26 22:05:19,814 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000048/fb-20200331_cal.xml\n",
      "2023-10-26 22:05:20,437 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000048/fb-20200331_def.xml\n",
      "2023-10-26 22:05:20,508 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 615...\n",
      "2023-10-26 22:05:20,513 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 615...\n",
      "2023-10-26 22:05:20,600 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000048...\n",
      "\n",
      "Gathering xml-data:  71%|███████   | 32/45 [03:55<01:45,  8.10s/it, accessionNumber=0001326801-20-000048, cik=0001326801, ticker=META]2023-10-26 22:05:20,601 - sec-scraper - INFO - 2020-07-31: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000076\n",
      "Gathering xml-data:  71%|███████   | 32/45 [03:55<01:45,  8.10s/it, accessionNumber=0001326801-20-000076, cik=0001326801, ticker=META]2023-10-26 22:05:20,602 - sec-scraper - INFO - Gathering xml-data:  71%|███████   | 32/45 [03:55<01:45,  8.10s/it, accessionNumber=0001326801-20-000076, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:05:21,707 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000076/0001326801-20-000076.txt\n",
      "2023-10-26 22:05:28,186 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000076/0001326801-20-000076.txt successfully.\n",
      "2023-10-26 22:05:28,188 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000076...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:05:28,605 - sec-scraper - ERROR - Failed to scrape context for https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000076...list index out of range\n",
      "2023-10-26 22:05:29,164 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000076/index.json\n",
      "2023-10-26 22:05:29,918 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000076/fb-20200630_lab.xml\n",
      "2023-10-26 22:05:30,828 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000076/fb-20200630_cal.xml\n",
      "2023-10-26 22:05:31,483 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000076/fb-20200630_def.xml\n",
      "2023-10-26 22:05:31,561 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 782...\n",
      "2023-10-26 22:05:31,567 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 782...\n",
      "2023-10-26 22:05:31,674 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000076...\n",
      "\n",
      "Gathering xml-data:  73%|███████▎  | 33/45 [04:06<01:47,  8.99s/it, accessionNumber=0001326801-20-000076, cik=0001326801, ticker=META]2023-10-26 22:05:31,675 - sec-scraper - INFO - 2020-10-30: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000084\n",
      "Gathering xml-data:  73%|███████▎  | 33/45 [04:06<01:47,  8.99s/it, accessionNumber=0001326801-20-000084, cik=0001326801, ticker=META]2023-10-26 22:05:31,677 - sec-scraper - INFO - Gathering xml-data:  73%|███████▎  | 33/45 [04:06<01:47,  8.99s/it, accessionNumber=0001326801-20-000084, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:05:32,808 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000084/0001326801-20-000084.txt\n",
      "2023-10-26 22:05:37,815 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000084/0001326801-20-000084.txt successfully.\n",
      "2023-10-26 22:05:37,817 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000084...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:05:38,270 - sec-scraper - ERROR - Failed to scrape context for https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000084...list index out of range\n",
      "2023-10-26 22:05:38,763 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000084/index.json\n",
      "2023-10-26 22:05:39,409 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000084/fb-20200930_lab.xml\n",
      "2023-10-26 22:05:40,390 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000084/fb-20200930_cal.xml\n",
      "2023-10-26 22:05:41,131 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000084/fb-20200930_def.xml\n",
      "2023-10-26 22:05:41,210 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 785...\n",
      "2023-10-26 22:05:41,216 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 785...\n",
      "2023-10-26 22:05:41,325 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680120000084...\n",
      "\n",
      "Gathering xml-data:  76%|███████▌  | 34/45 [04:16<01:41,  9.19s/it, accessionNumber=0001326801-20-000084, cik=0001326801, ticker=META]2023-10-26 22:05:41,327 - sec-scraper - INFO - 2021-01-28: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000014\n",
      "Gathering xml-data:  76%|███████▌  | 34/45 [04:16<01:41,  9.19s/it, accessionNumber=0001326801-21-000014, cik=0001326801, ticker=META]2023-10-26 22:05:41,328 - sec-scraper - INFO - Gathering xml-data:  76%|███████▌  | 34/45 [04:16<01:41,  9.19s/it, accessionNumber=0001326801-21-000014, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:05:41,914 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000014/0001326801-21-000014.txt\n",
      "2023-10-26 22:05:49,416 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000014/0001326801-21-000014.txt successfully.\n",
      "2023-10-26 22:05:49,419 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000014...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:05:50,396 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000014/index.json\n",
      "2023-10-26 22:05:51,119 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000014/fb-20201231_lab.xml\n",
      "2023-10-26 22:05:51,901 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000014/fb-20201231_cal.xml\n",
      "2023-10-26 22:05:52,590 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000014/fb-20201231_def.xml\n",
      "2023-10-26 22:05:52,675 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 923...\n",
      "2023-10-26 22:05:52,680 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 923...\n",
      "2023-10-26 22:05:52,781 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000014...\n",
      "\n",
      "Gathering xml-data:  78%|███████▊  | 35/45 [04:28<01:38,  9.87s/it, accessionNumber=0001326801-21-000014, cik=0001326801, ticker=META]2023-10-26 22:05:52,783 - sec-scraper - INFO - 2021-04-29: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000033\n",
      "Gathering xml-data:  78%|███████▊  | 35/45 [04:28<01:38,  9.87s/it, accessionNumber=0001326801-21-000033, cik=0001326801, ticker=META]2023-10-26 22:05:52,784 - sec-scraper - INFO - Gathering xml-data:  78%|███████▊  | 35/45 [04:28<01:38,  9.87s/it, accessionNumber=0001326801-21-000033, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:05:54,262 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000033/0001326801-21-000033.txt\n",
      "2023-10-26 22:05:58,410 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000033/0001326801-21-000033.txt successfully.\n",
      "2023-10-26 22:05:58,412 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000033...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:05:59,240 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000033/index.json\n",
      "2023-10-26 22:05:59,864 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000033/fb-20210331_lab.xml\n",
      "2023-10-26 22:06:00,642 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000033/fb-20210331_cal.xml\n",
      "2023-10-26 22:06:01,280 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000033/fb-20210331_def.xml\n",
      "2023-10-26 22:06:01,363 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 567...\n",
      "2023-10-26 22:06:01,369 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 567...\n",
      "2023-10-26 22:06:01,471 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000033...\n",
      "\n",
      "Gathering xml-data:  80%|████████  | 36/45 [04:36<01:25,  9.52s/it, accessionNumber=0001326801-21-000033, cik=0001326801, ticker=META]2023-10-26 22:06:01,473 - sec-scraper - INFO - 2021-07-29: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000049\n",
      "Gathering xml-data:  80%|████████  | 36/45 [04:36<01:25,  9.52s/it, accessionNumber=0001326801-21-000049, cik=0001326801, ticker=META]2023-10-26 22:06:01,474 - sec-scraper - INFO - Gathering xml-data:  80%|████████  | 36/45 [04:36<01:25,  9.52s/it, accessionNumber=0001326801-21-000049, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:06:02,375 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000049/0001326801-21-000049.txt\n",
      "2023-10-26 22:06:06,262 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000049/0001326801-21-000049.txt successfully.\n",
      "2023-10-26 22:06:06,265 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000049...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:06:07,156 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000049/index.json\n",
      "2023-10-26 22:06:07,941 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000049/fb-20210630_lab.xml\n",
      "2023-10-26 22:06:08,724 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000049/fb-20210630_cal.xml\n",
      "2023-10-26 22:06:09,436 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000049/fb-20210630_def.xml\n",
      "2023-10-26 22:06:09,519 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 737...\n",
      "2023-10-26 22:06:09,525 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 737...\n",
      "2023-10-26 22:06:09,626 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000049...\n",
      "\n",
      "Gathering xml-data:  82%|████████▏ | 37/45 [04:44<01:12,  9.11s/it, accessionNumber=0001326801-21-000049, cik=0001326801, ticker=META]2023-10-26 22:06:09,628 - sec-scraper - INFO - 2021-10-26: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000065\n",
      "Gathering xml-data:  82%|████████▏ | 37/45 [04:44<01:12,  9.11s/it, accessionNumber=0001326801-21-000065, cik=0001326801, ticker=META]2023-10-26 22:06:09,629 - sec-scraper - INFO - Gathering xml-data:  82%|████████▏ | 37/45 [04:44<01:12,  9.11s/it, accessionNumber=0001326801-21-000065, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:06:10,802 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000065/0001326801-21-000065.txt\n",
      "2023-10-26 22:06:15,387 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000065/0001326801-21-000065.txt successfully.\n",
      "2023-10-26 22:06:15,389 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000065...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:06:16,272 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000065/index.json\n",
      "2023-10-26 22:06:17,031 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000065/fb-20210930_lab.xml\n",
      "2023-10-26 22:06:17,831 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000065/fb-20210930_cal.xml\n",
      "2023-10-26 22:06:18,597 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000065/fb-20210930_def.xml\n",
      "2023-10-26 22:06:18,684 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 744...\n",
      "2023-10-26 22:06:18,690 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 744...\n",
      "2023-10-26 22:06:18,804 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680121000065...\n",
      "\n",
      "Gathering xml-data:  84%|████████▍ | 38/45 [04:54<01:03,  9.13s/it, accessionNumber=0001326801-21-000065, cik=0001326801, ticker=META]2023-10-26 22:06:18,806 - sec-scraper - INFO - 2022-02-03: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000018\n",
      "Gathering xml-data:  84%|████████▍ | 38/45 [04:54<01:03,  9.13s/it, accessionNumber=0001326801-22-000018, cik=0001326801, ticker=META]2023-10-26 22:06:18,807 - sec-scraper - INFO - Gathering xml-data:  84%|████████▍ | 38/45 [04:54<01:03,  9.13s/it, accessionNumber=0001326801-22-000018, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:06:19,650 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000018/0001326801-22-000018.txt\n",
      "2023-10-26 22:06:37,099 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000018/0001326801-22-000018.txt successfully.\n",
      "2023-10-26 22:06:37,101 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000018...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:06:37,680 - sec-scraper - ERROR - Failed to scrape context for https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000018...list index out of range\n",
      "2023-10-26 22:06:38,172 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000018/index.json\n",
      "2023-10-26 22:06:38,852 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000018/fb-20211231_lab.xml\n",
      "2023-10-26 22:06:39,782 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000018/fb-20211231_cal.xml\n",
      "2023-10-26 22:06:40,528 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000018/fb-20211231_def.xml\n",
      "2023-10-26 22:06:40,621 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 935...\n",
      "2023-10-26 22:06:40,627 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 935...\n",
      "2023-10-26 22:06:40,737 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000018...\n",
      "\n",
      "Gathering xml-data:  87%|████████▋ | 39/45 [05:16<01:17, 12.97s/it, accessionNumber=0001326801-22-000018, cik=0001326801, ticker=META]2023-10-26 22:06:40,738 - sec-scraper - INFO - 2022-04-28: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000057\n",
      "Gathering xml-data:  87%|████████▋ | 39/45 [05:16<01:17, 12.97s/it, accessionNumber=0001326801-22-000057, cik=0001326801, ticker=META]2023-10-26 22:06:40,740 - sec-scraper - INFO - Gathering xml-data:  87%|████████▋ | 39/45 [05:16<01:17, 12.97s/it, accessionNumber=0001326801-22-000057, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:06:41,606 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000057/0001326801-22-000057.txt\n",
      "2023-10-26 22:06:48,086 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000057/0001326801-22-000057.txt successfully.\n",
      "2023-10-26 22:06:48,089 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000057...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:06:48,961 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000057/index.json\n",
      "2023-10-26 22:06:49,641 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000057/meta-20220331_lab.xml\n",
      "2023-10-26 22:06:50,589 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000057/meta-20220331_cal.xml\n",
      "2023-10-26 22:06:51,331 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000057/meta-20220331_def.xml\n",
      "2023-10-26 22:06:51,423 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 641...\n",
      "2023-10-26 22:06:51,428 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 641...\n",
      "2023-10-26 22:06:51,541 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000057...\n",
      "\n",
      "Gathering xml-data:  89%|████████▉ | 40/45 [05:26<01:01, 12.32s/it, accessionNumber=0001326801-22-000057, cik=0001326801, ticker=META]2023-10-26 22:06:51,543 - sec-scraper - INFO - 2022-07-28: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000082\n",
      "Gathering xml-data:  89%|████████▉ | 40/45 [05:26<01:01, 12.32s/it, accessionNumber=0001326801-22-000082, cik=0001326801, ticker=META]2023-10-26 22:06:51,544 - sec-scraper - INFO - Gathering xml-data:  89%|████████▉ | 40/45 [05:26<01:01, 12.32s/it, accessionNumber=0001326801-22-000082, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:06:52,520 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000082/0001326801-22-000082.txt\n",
      "2023-10-26 22:06:56,685 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000082/0001326801-22-000082.txt successfully.\n",
      "2023-10-26 22:06:56,687 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000082...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:06:57,604 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000082/index.json\n",
      "2023-10-26 22:06:58,235 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000082/meta-20220630_lab.xml\n",
      "2023-10-26 22:06:59,248 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000082/meta-20220630_cal.xml\n",
      "2023-10-26 22:06:59,926 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000082/meta-20220630_def.xml\n",
      "2023-10-26 22:07:00,040 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 885...\n",
      "2023-10-26 22:07:00,046 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 885...\n",
      "2023-10-26 22:07:00,159 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000082...\n",
      "\n",
      "Gathering xml-data:  91%|█████████ | 41/45 [05:35<00:44, 11.21s/it, accessionNumber=0001326801-22-000082, cik=0001326801, ticker=META]2023-10-26 22:07:00,161 - sec-scraper - INFO - 2022-10-27: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000108\n",
      "Gathering xml-data:  91%|█████████ | 41/45 [05:35<00:44, 11.21s/it, accessionNumber=0001326801-22-000108, cik=0001326801, ticker=META]2023-10-26 22:07:00,162 - sec-scraper - INFO - Gathering xml-data:  91%|█████████ | 41/45 [05:35<00:44, 11.21s/it, accessionNumber=0001326801-22-000108, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:07:00,808 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000108/0001326801-22-000108.txt\n",
      "2023-10-26 22:07:04,419 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000108/0001326801-22-000108.txt successfully.\n",
      "2023-10-26 22:07:04,421 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000108...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:07:05,337 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000108/index.json\n",
      "2023-10-26 22:07:06,047 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000108/meta-20220930_lab.xml\n",
      "2023-10-26 22:07:06,973 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000108/meta-20220930_cal.xml\n",
      "2023-10-26 22:07:07,831 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000108/meta-20220930_def.xml\n",
      "2023-10-26 22:07:07,932 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 922...\n",
      "2023-10-26 22:07:07,938 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 922...\n",
      "2023-10-26 22:07:08,060 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680122000108...\n",
      "\n",
      "Gathering xml-data:  93%|█████████▎| 42/45 [05:43<00:30, 10.22s/it, accessionNumber=0001326801-22-000108, cik=0001326801, ticker=META]2023-10-26 22:07:08,062 - sec-scraper - INFO - 2023-02-02: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000013\n",
      "Gathering xml-data:  93%|█████████▎| 42/45 [05:43<00:30, 10.22s/it, accessionNumber=0001326801-23-000013, cik=0001326801, ticker=META]2023-10-26 22:07:08,063 - sec-scraper - INFO - Gathering xml-data:  93%|█████████▎| 42/45 [05:43<00:30, 10.22s/it, accessionNumber=0001326801-23-000013, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:07:08,767 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000013/0001326801-23-000013.txt\n",
      "2023-10-26 22:07:11,250 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000013/0001326801-23-000013.txt successfully.\n",
      "2023-10-26 22:07:11,252 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000013...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:07:12,355 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000013/index.json\n",
      "2023-10-26 22:07:13,036 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000013/meta-20221231_lab.xml\n",
      "2023-10-26 22:07:13,844 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000013/meta-20221231_cal.xml\n",
      "2023-10-26 22:07:14,417 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000013/meta-20221231_def.xml\n",
      "2023-10-26 22:07:14,526 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 1115...\n",
      "2023-10-26 22:07:14,532 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 1115...\n",
      "2023-10-26 22:07:14,655 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000013...\n",
      "\n",
      "Gathering xml-data:  96%|█████████▌| 43/45 [05:49<00:18,  9.13s/it, accessionNumber=0001326801-23-000013, cik=0001326801, ticker=META]2023-10-26 22:07:14,657 - sec-scraper - INFO - 2023-04-27: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000067\n",
      "Gathering xml-data:  96%|█████████▌| 43/45 [05:49<00:18,  9.13s/it, accessionNumber=0001326801-23-000067, cik=0001326801, ticker=META]2023-10-26 22:07:14,658 - sec-scraper - INFO - Gathering xml-data:  96%|█████████▌| 43/45 [05:49<00:18,  9.13s/it, accessionNumber=0001326801-23-000067, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:07:15,321 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000067/0001326801-23-000067.txt\n",
      "2023-10-26 22:07:22,381 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000067/0001326801-23-000067.txt successfully.\n",
      "2023-10-26 22:07:22,383 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000067...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:07:22,825 - sec-scraper - ERROR - Failed to scrape context for https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000067...list index out of range\n",
      "2023-10-26 22:07:23,353 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000067/index.json\n",
      "2023-10-26 22:07:24,061 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000067/meta-20230331_lab.xml\n",
      "2023-10-26 22:07:24,872 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000067/meta-20230331_cal.xml\n",
      "2023-10-26 22:07:25,481 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000067/meta-20230331_def.xml\n",
      "2023-10-26 22:07:25,589 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 810...\n",
      "2023-10-26 22:07:25,595 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 810...\n",
      "2023-10-26 22:07:25,721 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000067...\n",
      "\n",
      "Gathering xml-data:  98%|█████████▊| 44/45 [06:01<00:09,  9.71s/it, accessionNumber=0001326801-23-000067, cik=0001326801, ticker=META]2023-10-26 22:07:25,722 - sec-scraper - INFO - 2023-07-27: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000093\n",
      "Gathering xml-data:  98%|█████████▊| 44/45 [06:01<00:09,  9.71s/it, accessionNumber=0001326801-23-000093, cik=0001326801, ticker=META]2023-10-26 22:07:25,723 - sec-scraper - INFO - Gathering xml-data:  98%|█████████▊| 44/45 [06:01<00:09,  9.71s/it, accessionNumber=0001326801-23-000093, cik=0001326801, ticker=META]\n",
      "2023-10-26 22:07:26,317 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000093/0001326801-23-000093.txt\n",
      "2023-10-26 22:07:29,235 - sec-scraper - INFO - Parsed file data from https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000093/0001326801-23-000093.txt successfully.\n",
      "2023-10-26 22:07:29,238 - sec-scraper - ERROR - Failed to scrape metalinks for https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000093...TickerData.get_metalinks() got an unexpected keyword argument 'folder_url'\n",
      "2023-10-26 22:07:31,502 - sec-scraper - ERROR - Failed to scrape context for https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000093...list index out of range\n",
      "2023-10-26 22:07:31,992 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000093/index.json\n",
      "2023-10-26 22:07:32,558 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000093/meta-20230630_lab.xml\n",
      "2023-10-26 22:07:33,229 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000093/meta-20230630_cal.xml\n",
      "2023-10-26 22:07:33,838 - sec-scraper - INFO - Request successful at URL: https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000093/meta-20230630_def.xml\n",
      "2023-10-26 22:07:33,950 - sec-scraper - INFO - Merging facts with context and labels. Current facts length: 1034...\n",
      "2023-10-26 22:07:33,957 - sec-scraper - INFO - Successfully merged facts with context and labels. Merged facts length: 1034...\n",
      "2023-10-26 22:07:34,089 - sec-scraper - INFO - Successfully scraped META(0001326801)-https://www.sec.gov/Archives/edgar/data/0001326801/000132680123000093...\n",
      "\n",
      "Gathering xml-data: 100%|██████████| 45/45 [06:09<00:00,  8.21s/it, accessionNumber=0001326801-23-000093, cik=0001326801, ticker=META]\n"
     ]
    }
   ],
   "source": [
    "ticker = TickerData('META')\n",
    "\n",
    "start_date = dt.datetime(2009, 6, 1) # after XBRL implementation\n",
    "query = {\n",
    "    'cik': ticker.cik,\n",
    "    'form': {'$in': ['10-K', '10-Q']},\n",
    "    'filingDate': {'$gte': start_date},\n",
    "}\n",
    "filings_to_scrape = [i for i in mongo.tickerfilings.find(query).sort('filingDate', 1)]\n",
    "\n",
    "all_labels = pd.DataFrame()\n",
    "all_calc = pd.DataFrame()\n",
    "all_defn = pd.DataFrame()\n",
    "all_context = pd.DataFrame()\n",
    "all_facts = pd.DataFrame()\n",
    "all_metalinks = pd.DataFrame()\n",
    "all_merged_facts = pd.DataFrame()\n",
    "failed_folders = []\n",
    "\n",
    "with trange(len(filings_to_scrape[:]), desc='Gathering xml-data',) as t:\n",
    "    for file in t:\n",
    "        file = filings_to_scrape[file]\n",
    "        if (file.get('form') != '10-Q' or file.get('form') != '10-K') and file.get('filingDate') < dt.datetime(2009, 1, 1):\n",
    "            continue\n",
    "        \n",
    "        # if file.get('accessionNumber') != \"0001564590-20-002450\":\n",
    "        #     continue\n",
    "        \n",
    "        accessionNumber = file.get('accessionNumber')\n",
    "        folder_url = file.get('folder_url')\n",
    "        file_url = file.get('file_url')\n",
    "        ticker.scrape_logger.info(file.get('filingDate').strftime('%Y-%m-%d') + ': ' + folder_url)\n",
    "        t.set_postfix(ticker=ticker.ticker, cik=ticker.cik, accessionNumber=accessionNumber)\n",
    "        ticker.scrape_logger.info(f'{t}')\n",
    "\n",
    "        soup = ticker.get_file_data(file_url=file_url)\n",
    "\n",
    "        # Scrape facts, context, metalinks\n",
    "        try:\n",
    "            metalinks_url = folder_url + '/MetaLinks.json'\n",
    "            metalinks = ticker.get_metalinks(folder_url=metalinks_url)\n",
    "            metalinks['accessionNumber'] = accessionNumber\n",
    "            all_metalinks = pd.concat([all_metalinks, metalinks], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            ticker.scrape_logger.error(f'Failed to scrape metalinks for {folder_url}...{e}')\n",
    "            failed_folders.append(dict(folder_url=folder_url, accessionNumber=accessionNumber, error=f'Failed to scrape metalinks for {folder_url}...{e}', filingDate=file.get('filingDate')))\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            facts = ticker.search_facts(soup=soup)\n",
    "            facts['accessionNumber'] = accessionNumber\n",
    "            all_facts = pd.concat([all_facts, facts], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            ticker.scrape_logger.error(f'Failed to scrape facts for {folder_url}...{e}')\n",
    "            failed_folders.append(dict(folder_url=folder_url, accessionNumber=accessionNumber, error=f'Failed to scrape facts for {folder_url}...{e}', filingDate=file.get('filingDate')))\n",
    "            pass\n",
    "        try:\n",
    "            context = ticker.search_context(soup=soup)\n",
    "            context['accessionNumber'] = accessionNumber\n",
    "            all_context = pd.concat([all_context, context], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            ticker.scrape_logger.error(f'Failed to scrape context for {folder_url}...{e}')\n",
    "            failed_folders.append(dict(folder_url=folder_url, accessionNumber=accessionNumber, error=f'Failed to scrape context for {folder_url}...{e}', filingDate=file.get('filingDate')))\n",
    "            pass\n",
    "\n",
    "        index_df = ticker.get_filing_folder_index(folder_url=folder_url)\n",
    "\n",
    "\n",
    "        try: # Scrape labels\n",
    "            labels = ticker.get_elements(folder_url=folder_url, index_df=index_df, scrape_file_extension='_lab').query(\"`xlink:type` == 'resource'\")\n",
    "            labels['xlink:role'] = labels['xlink:role'].str.split('/').apply(lambda x: x[-1])\n",
    "            labels['xlink:label'] = labels['xlink:label'].str.split('_').apply(lambda x: ':'.join(x[:2])).str.lower()\n",
    "            labels['accessionNumber'] = accessionNumber\n",
    "            all_labels = pd.concat([all_labels, labels], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            ticker.scrape_logger.error(f'Failed to scrape labels for {folder_url}...{e}')\n",
    "            failed_folders.append(dict(folder_url=folder_url, accessionNumber=accessionNumber, error=f'Failed to scrape labels for {folder_url}...{e}', filingDate=file.get('filingDate')))\n",
    "            pass\n",
    "\n",
    "        try: # Scrape calculations\n",
    "            calc = ticker.get_elements(folder_url=folder_url, index_df=index_df, scrape_file_extension='_cal').query(\"`xlink:type` == 'arc'\")\n",
    "            calc['accessionNumber'] = accessionNumber\n",
    "            all_calc = pd.concat([all_calc, calc], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            ticker.scrape_logger.error(f'Failed to scrape calc for {folder_url}...{e}')\n",
    "            failed_folders.append(dict(folder_url=folder_url, accessionNumber=accessionNumber, error=f'Failed to scrape calc for {folder_url}...{e}', filingDate=file.get('filingDate')))\n",
    "            pass\n",
    "\n",
    "        try: # Scrape definitions\n",
    "            defn = ticker.get_elements(folder_url=folder_url, index_df=index_df, scrape_file_extension='_def').query(\"`xlink:type` == 'arc'\")\n",
    "            defn['accessionNumber'] = accessionNumber\n",
    "            all_defn = pd.concat([all_defn, defn], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            ticker.scrape_logger.error(f'Failed to scrape defn for {folder_url}...{e}')\n",
    "            failed_folders.append(dict(folder_url=folder_url, accessionNumber=accessionNumber, error=f'Failed to scrape defn for {folder_url}...{e}', filingDate=file.get('filingDate')))\n",
    "            pass\n",
    "\n",
    "        if len(facts) == 0:\n",
    "            ticker.scrape_logger.info(f'No facts found for {ticker.ticker}({ticker.cik})-{folder_url}...\\n')\n",
    "            continue\n",
    "\n",
    "        ticker.scrape_logger.info(f'Merging facts with context and labels. Current facts length: {len(facts)}...')\n",
    "        merged_facts = facts.merge(context, how='left', left_on='contextRef', right_on='contextId')\\\n",
    "                                    .merge(labels.query(\"`xlink:role` == 'label'\"), how='left', left_on='factName', right_on='xlink:label')\n",
    "        ticker.scrape_logger.info(f'Successfully merged facts with context and labels. Merged facts length: {len(merged_facts)}...')\n",
    "        all_merged_facts = pd.concat([all_merged_facts, merged_facts], ignore_index=True)\n",
    "        ticker.scrape_logger.info(f'Successfully scraped {ticker.ticker}({ticker.cik})-{folder_url}...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all_labels, all_calc, all_defn to xlsx on different sheets\n",
    "with pd.ExcelWriter(f'././data/{ticker.ticker}_all_data.xlsx') as writer:\n",
    "    all_facts.to_excel(writer, sheet_name='facts', index=False)\n",
    "    all_context.to_excel(writer, sheet_name='context', index=False)\n",
    "    all_labels.to_excel(writer, sheet_name='labels', index=False)\n",
    "    all_merged_facts.to_excel(writer, sheet_name='merged_facts', index=False)\n",
    "    all_calc.to_excel(writer, sheet_name='calc', index=False)\n",
    "    all_defn.to_excel(writer, sheet_name='defn', index=False)\n",
    "    all_metalinks.to_excel(writer, sheet_name='metalinks', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop through all filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = SECData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = TickerData(ticker='V')\n",
    "soup = symbol.get_file_data(symbol.filings.loc[symbol.filings['form'] == '10-K', 'file_url'].iloc[0])\n",
    "\n",
    "contexts = symbol.search_tags(soup, '^context$')\n",
    "dict_list = []\n",
    "columns = {'contextId': str, 'entity': str, 'segment': str,\n",
    "            'startDate': 'datetime64[ns]', 'endDate': 'datetime64[ns]', 'instant': 'datetime64[ns]'}\n",
    "for tag in contexts:\n",
    "    temp_dict = {}\n",
    "    temp_dict['contextId'] = tag.attrs.get('id')\n",
    "    temp_dict['entity'] = tag.find(\"entity\").text.split()[\n",
    "        0] if tag.find(\"entity\").text is not None else None\n",
    "    temp_dict['segment'] = tag.find(\"segment\").text.strip(\n",
    "    ) if tag.find(\"segment\") is not None else None\n",
    "    temp_dict['startDate'] = tag.find(\"startdate\").text if tag.find(\n",
    "        \"startdate\") is not None else None\n",
    "    temp_dict['endDate'] = tag.find(\"enddate\").text if tag.find(\n",
    "        \"enddate\") is not None else None\n",
    "    temp_dict['instant'] = tag.find(\"instant\").text if tag.find(\n",
    "        \"instant\") is not None else None\n",
    "    dict_list.append(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse using GPT (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = symbol.search_context(soup)[0]\n",
    "data = {\n",
    "    'id': context['id'],\n",
    "    'entity': {\n",
    "        'identifier': {\n",
    "            'scheme': context.find('identifier')['scheme'],\n",
    "            'value': context.find('identifier').text\n",
    "        }\n",
    "    },\n",
    "    'period': {\n",
    "        'startDate': context.find('startdate').text,\n",
    "        'endDate': context.find('enddate').text\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import XMLOutputParser\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessage,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import json\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "parser = XMLOutputParser(tags=['id', 'entity', 'period'])\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that parses XML files for a company's financial statements from the SEC Edgar database.\"\n",
    "                \"The XML content will be provided by the user.\"\n",
    "                \"You will parse the output and return it in the json format.\"\n",
    "                \"{format_instructions}\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{xml}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "context_list = []\n",
    "total_cost = 0\n",
    "total_tokens = 0\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "with trange(len(contexts[:]), desc='Scraping contexts...') as t:\n",
    "    for i in t:\n",
    "        with get_openai_callback() as cb:\n",
    "            t.set_postfix(context=contexts[i].attrs.get('id'))\n",
    "            output = llm(template.format_messages(format_instructions=parser.get_format_instructions(), xml=contexts[i]))\n",
    "            total_cost += cb.total_cost\n",
    "            total_tokens += cb.total_tokens\n",
    "            context_list.append(json.loads(output.content))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
